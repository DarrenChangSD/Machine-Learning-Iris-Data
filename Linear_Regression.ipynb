{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression generally have the form of $Y_{i} = \\theta_{0} + \\theta_{1} x_{1} + \\theta_{2} x_{2} + ...$ <br>\n",
    "There are several ways to find the coefficients of the regression: <br>\n",
    "1. Linear Algebra: $\\hat{\\theta} = (X^{T}X)^{-1}X^{T}Y$ (When X is invertible) <br>\n",
    "2. Gradient Descent: In this case, we need to write out the loss function and try to minimize the loss. <br>\n",
    "$\\hspace{30mm}$ $F(x)$ = Loss Function = SE = $ \\sum^{n}_{i=1} (Y_{i} - \\hat{Y_{i}})^{2}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression():\n",
    "    def __init__(self, alpha = 1e-10 , num_iter = 10000, early_stop = 1e-50, intercept = True, init_weight = None):\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "            \n",
    "            attributes: \n",
    "                        alpha: Learning Rate, default 1e-10\n",
    "                        num_iter: Number of Iterations to update coefficient with training data\n",
    "                        early_stop: Constant control early_stop.\n",
    "                        intercept: Bool, If we are going to fit a intercept, default True.\n",
    "                        init_weight: Matrix (n x 1), input init_weight for testing.\n",
    "                        \n",
    "            \n",
    "            TODO: 1. Initialize all variables needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_name = 'Linear Regression'\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.num_iter = num_iter\n",
    "        self.early_stop = early_stop\n",
    "        self.intercept = intercept\n",
    "        self.init_weight = init_weight  ### For testing correctness.\n",
    "        \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "            Save the datasets in our model, and perform gradient descent.\n",
    "            \n",
    "            Parameter:\n",
    "                X_train: Matrix or 2-D array. Input feature matrix.\n",
    "                Y_train: Matrix or 2-D array. Input target value.\n",
    "                \n",
    "                \n",
    "                TODO: 2. If we are going to fit the intercept, add a col with all 1's to the first column. (hint: np.hstack, np.ones)\n",
    "                      3. Initilaize our coef with uniform from [-1, 1] with the number of col in training set.\n",
    "                      4. Call the gradient_descent function to train.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = np.mat(X_train)\n",
    "        self.y = np.mat(y_train)\n",
    "        \n",
    "        if self.intercept:\n",
    "            ones = np.ones(len(self.X)).reshape(-1, 1)\n",
    "            self.X = np.hstack([ones, self.X])\n",
    "        \n",
    "        #print(self.X)\n",
    "        self.coef = np.random.uniform(-1, 1, self.X.shape[1])\n",
    "        self.gradient_descent()\n",
    "        #self.coef = self.init_weight #### Please change this after you get the example right.\n",
    "        \n",
    "    def gradient(self):\n",
    "        \"\"\"\n",
    "            Helper function to calculate the gradient respect to coefficient.\n",
    "            \n",
    "            TODO: 5. Think about the matrix format of the gradient of the loss function.\n",
    "        \"\"\"\n",
    "        y_pred = self.X.dot(self.coef)\n",
    "        self.grad_coef = np.array(-(self.y - y_pred).dot(self.X)).flatten()\n",
    "        #self.grad_coef = 0\n",
    "        \n",
    "    def gradient_descent(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Training function\n",
    "            \n",
    "            TODO: 6. Calculate the loss with current coefficients.\n",
    "                  7. Update the temp_coef with learning rate and gradient.\n",
    "                  8. Calculate the loss with temp_coef.\n",
    "                  9. Implement the self adeptive learning rate. \n",
    "                      a. If current error is less than previous error, increase learning rate by a factor 1.3. \n",
    "                         And update coef, with temp_coef.\n",
    "                      b. If previous error is less than current error, decrease learning rate by a factor of 0.9.\n",
    "                         Don't update coef.\n",
    "                  10. Add the loss to loss list we create.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.loss = []\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "\n",
    "                \n",
    "                \n",
    "            self.gradient()\n",
    "\n",
    "            \n",
    "            previous_y_hat = self.X.dot(self.coef)\n",
    "            \n",
    "            \n",
    "            temp_coef = self.coef - self.alpha * self.grad_coef\n",
    "            \n",
    "            #ones = 0  # Matrix with 1's (1 x n), help with calculate the sum of a mattrix. hint: Think about dot product.\n",
    "            \n",
    "            pre_error = np.mean(0.5 * np.square(self.y - previous_y_hat))\n",
    "            \n",
    "            current_error = np.mean(0.5 * np.square(self.y - self.X.dot(temp_coef)))\n",
    "            \n",
    "            ### This is the early stop, don't modify fllowing three lines.\n",
    "            if (abs(pre_error - current_error) < self.early_stop) | (abs(abs(pre_error - current_error) / pre_error) < self.early_stop):\n",
    "                self.coef = temp_coef\n",
    "                return self\n",
    "            \n",
    "            if current_error <= pre_error:\n",
    "                self.alpha *= 1.3\n",
    "                self.coef = temp_coef\n",
    "            else:\n",
    "                self.alpha *= 0.9\n",
    "                \n",
    "            self.loss.append(current_error)\n",
    "            \n",
    "            if i % 10000 == 0:\n",
    "                print('Iteration: ' +  str(i))\n",
    "                print('Coef: '+ str(self.coef))\n",
    "                print('Loss: ' + str(current_error))            \n",
    "        return self\n",
    "    \n",
    "    def ind_predict(self, x: list):\n",
    "        \"\"\"\n",
    "            Predict the value based on its feature vector x.\n",
    "\n",
    "            Parameter:\n",
    "            x: Matrix, array or list. Input feature point.\n",
    "            \n",
    "            Return:\n",
    "                result: prediction of given data point\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 11. Implement the prediction function\n",
    "        \"\"\"\n",
    "        result = 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X is a matrix or 2-D numpy array, represnting testing instances. \n",
    "            Each testing instance is a feature vector. \n",
    "            \n",
    "            Parameter:\n",
    "            X: Matrix, array or list. Input feature point.\n",
    "            \n",
    "            Return:\n",
    "                ret: prediction of given data matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 12. Make sure add the 1's column like we did to add intercept.\n",
    "                  13. Revise the following for-loop to call ind_predict to get predictions.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.mat(X)\n",
    "        if self.intercept:\n",
    "            ones = np.ones(X.shape[0]).reshape(-1, 1)\n",
    "            X = np.hstack([ones, X])\n",
    "        ret = [np.array(x).dot(self.coef)[0] for x in X]\n",
    "        return ret\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(np.mat(np.arange(1, 1000, 5)).T)\n",
    "y = np.array((30 * X)).flatten() +  20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Coef: [-0.78310295 -0.50009803]\n",
      "Loss: 6.812143356038825e+23\n",
      "Iteration: 10000\n",
      "Coef: [-0.64905035 30.03108386]\n",
      "Loss: 53.538141211590826\n",
      "Iteration: 20000\n",
      "Coef: [-0.55961158 30.0308198 ]\n",
      "Loss: 53.07629495438401\n",
      "Iteration: 30000\n",
      "Coef: [-0.47055681 30.03083743]\n",
      "Loss: 52.61806585107836\n",
      "Iteration: 40000\n",
      "Coef: [-0.38189466 30.03054797]\n",
      "Loss: 52.16218568435227\n",
      "Iteration: 50000\n",
      "Coef: [-0.29358143 30.03040865]\n",
      "Loss: 51.71106178356396\n",
      "Iteration: 60000\n",
      "Coef: [-0.20568492 30.03042373]\n",
      "Loss: 51.263897939780485\n",
      "Iteration: 70000\n",
      "Coef: [-0.11816604 30.0301483 ]\n",
      "Loss: 50.82206832356986\n",
      "Iteration: 80000\n",
      "Coef: [-0.03102559 30.0301694 ]\n",
      "Loss: 50.38244603988198\n",
      "Iteration: 90000\n",
      "Coef: [ 0.05573364 30.02989612]\n",
      "Loss: 49.94610183488889\n",
      "Iteration: 100000\n",
      "Coef: [ 0.14215128 30.02975871]\n",
      "Loss: 49.51420480818213\n",
      "Iteration: 110000\n",
      "Coef: [ 0.22816112 30.02976933]\n",
      "Loss: 49.086082042474644\n",
      "Iteration: 120000\n",
      "Coef: [ 0.31380168 30.02950164]\n",
      "Loss: 48.662999568623036\n",
      "Iteration: 130000\n",
      "Coef: [ 0.3990712  30.02952535]\n",
      "Loss: 48.24228144656835\n",
      "Iteration: 140000\n",
      "Coef: [ 0.48396488 30.02926182]\n",
      "Loss: 47.82407321027852\n",
      "Iteration: 150000\n",
      "Coef: [ 0.5685308  30.02911243]\n",
      "Loss: 47.41091733035747\n",
      "Iteration: 160000\n",
      "Coef: [ 0.65269151 30.02912396]\n",
      "Loss: 47.00068347466573\n",
      "Iteration: 170000\n",
      "Coef: [ 0.7364933  30.02887081]\n",
      "Loss: 46.59554913076263\n",
      "Iteration: 180000\n",
      "Coef: [ 0.8199328  30.02888892]\n",
      "Loss: 46.19272648203634\n",
      "Iteration: 190000\n",
      "Coef: [ 0.90300395 30.02863278]\n",
      "Loss: 45.79242875561607\n",
      "Iteration: 200000\n",
      "Coef: [ 0.98575421 30.02848192]\n",
      "Loss: 45.39694835172974\n",
      "Iteration: 210000\n",
      "Coef: [ 1.06810858 30.02850367]\n",
      "Loss: 45.00409685353875\n",
      "Iteration: 220000\n",
      "Coef: [ 1.15010848 30.02825708]\n",
      "Loss: 44.6157586924731\n",
      "Iteration: 230000\n",
      "Coef: [ 1.23175649 30.02826581]\n",
      "Loss: 44.23023863616299\n",
      "Iteration: 240000\n",
      "Coef: [ 1.3130476  30.02800652]\n",
      "Loss: 43.84740597268803\n",
      "Iteration: 250000\n",
      "Coef: [ 1.39401848 30.02786909]\n",
      "Loss: 43.468431376940714\n",
      "Iteration: 260000\n",
      "Coef: [ 1.47460168 30.02788384]\n",
      "Loss: 43.09209785976756\n",
      "Iteration: 270000\n",
      "Coef: [ 1.55484481 30.02764591]\n",
      "Loss: 42.720610260164165\n",
      "Iteration: 280000\n",
      "Coef: [ 1.63474017 30.02766656]\n",
      "Loss: 42.35160189454573\n",
      "Iteration: 290000\n",
      "Coef: [ 1.71428313 30.02740882]\n",
      "Loss: 41.984572407675394\n",
      "Iteration: 300000\n",
      "Coef: [ 1.79351596 30.02727334]\n",
      "Loss: 41.621741474787775\n",
      "Iteration: 310000\n",
      "Coef: [ 1.87236939 30.02728493]\n",
      "Loss: 41.26145876121102\n",
      "Iteration: 320000\n",
      "Coef: [ 1.9508894  30.02704755]\n",
      "Loss: 40.90600540774115\n",
      "Iteration: 330000\n",
      "Coef: [ 2.02906717 30.02706336]\n",
      "Loss: 40.552014752744974\n",
      "Iteration: 340000\n",
      "Coef: [ 2.10690295 30.02682689]\n",
      "Loss: 40.200808753707754\n",
      "Iteration: 350000\n",
      "Coef: [ 2.18443504 30.02669442]\n",
      "Loss: 39.85341348421789\n",
      "Iteration: 360000\n",
      "Coef: [ 2.26159887 30.02670639]\n",
      "Loss: 39.5097614944835\n",
      "Iteration: 370000\n",
      "Coef: [ 2.33843077 30.02647085]\n",
      "Loss: 39.16802469494378\n",
      "Iteration: 380000\n",
      "Coef: [ 2.41492996 30.02648224]\n",
      "Loss: 38.8292815923944\n",
      "Iteration: 390000\n",
      "Coef: [ 2.49109471 30.02624839]\n",
      "Loss: 38.493062400216466\n",
      "Iteration: 400000\n",
      "Coef: [ 2.56696234 30.02611505]\n",
      "Loss: 38.16050553630442\n",
      "Iteration: 410000\n",
      "Coef: [ 2.64246671 30.02612914]\n",
      "Loss: 37.83024581351796\n",
      "Iteration: 420000\n",
      "Coef: [ 2.71764936 30.02590466]\n",
      "Loss: 37.50398981971153\n",
      "Iteration: 430000\n",
      "Coef: [ 2.79250658 30.02591249]\n",
      "Loss: 37.179694333342965\n",
      "Iteration: 440000\n",
      "Coef: [ 2.8670364  30.02568411]\n",
      "Loss: 36.85782115282695\n",
      "Iteration: 450000\n",
      "Coef: [ 2.94127536 30.02555066]\n",
      "Loss: 36.53946405195777\n",
      "Iteration: 460000\n",
      "Coef: [ 3.01515897 30.02557254]\n",
      "Loss: 36.224204054798435\n",
      "Iteration: 470000\n",
      "Coef: [ 3.08872755 30.02534082]\n",
      "Loss: 35.91111938057883\n",
      "Iteration: 480000\n",
      "Coef: [ 3.16197793 30.0253665 ]\n",
      "Loss: 35.60066032201831\n",
      "Iteration: 490000\n",
      "Coef: [ 3.23490519 30.02513374]\n",
      "Loss: 35.29200517532564\n",
      "Iteration: 500000\n",
      "Coef: [ 3.30755065 30.02500208]\n",
      "Loss: 34.98719926462272\n",
      "Iteration: 510000\n",
      "Coef: [ 3.37984559 30.02501439]\n",
      "Loss: 34.68424896791097\n",
      "Iteration: 520000\n",
      "Coef: [ 3.45183463 30.02480367]\n",
      "Loss: 34.38521863078462\n",
      "Iteration: 530000\n",
      "Coef: [ 3.52351228 30.02481794]\n",
      "Loss: 34.08811539997918\n",
      "Iteration: 540000\n",
      "Coef: [ 3.59487686 30.02458456]\n",
      "Loss: 33.79298837968606\n",
      "Iteration: 550000\n",
      "Coef: [ 3.6659602  30.02446518]\n",
      "Loss: 33.500885595227174\n",
      "Iteration: 560000\n",
      "Coef: [ 3.73670327 30.02447882]\n",
      "Loss: 33.21082496421823\n",
      "Iteration: 570000\n",
      "Coef: [ 3.80714748 30.02426972]\n",
      "Loss: 32.92453066286369\n",
      "Iteration: 580000\n",
      "Coef: [ 3.8772839  30.02427587]\n",
      "Loss: 32.63964646802207\n",
      "Iteration: 590000\n",
      "Coef: [ 3.94711628 30.02406205]\n",
      "Loss: 32.35725973407241\n",
      "Iteration: 600000\n",
      "Coef: [ 4.01667366 30.02394388]\n",
      "Loss: 32.07762143196871\n",
      "Iteration: 610000\n",
      "Coef: [ 4.08589809 30.02395234]\n",
      "Loss: 31.799960275605745\n",
      "Iteration: 620000\n",
      "Coef: [ 4.15482998 30.02374715]\n",
      "Loss: 31.52590496095957\n",
      "Iteration: 630000\n",
      "Coef: [ 4.22346116 30.02375652]\n",
      "Loss: 31.25312015238503\n",
      "Iteration: 640000\n",
      "Coef: [ 4.29179477 30.02354302]\n",
      "Loss: 30.98272408310553\n",
      "Iteration: 650000\n",
      "Coef: [ 4.35985926 30.02342608]\n",
      "Loss: 30.714984939400985\n",
      "Iteration: 660000\n",
      "Coef: [ 4.42759771 30.0234421 ]\n",
      "Loss: 30.449097552583204\n",
      "Iteration: 670000\n",
      "Coef: [ 4.49505001 30.02323086]\n",
      "Loss: 30.18692055426867\n",
      "Iteration: 680000\n",
      "Coef: [ 4.56220545 30.02324293]\n",
      "Loss: 29.925313063666177\n",
      "Iteration: 690000\n",
      "Coef: [ 4.62907229 30.02303962]\n",
      "Loss: 29.666466292643058\n",
      "Iteration: 700000\n",
      "Coef: [ 4.69567546 30.0229223 ]\n",
      "Loss: 29.410173976680607\n",
      "Iteration: 710000\n",
      "Coef: [ 4.76195995 30.02294037]\n",
      "Loss: 29.156290711928477\n",
      "Iteration: 720000\n",
      "Coef: [ 4.82796205 30.02274087]\n",
      "Loss: 28.90412991130358\n",
      "Iteration: 730000\n",
      "Coef: [ 4.89367828 30.02274862]\n",
      "Loss: 28.654181729408336\n",
      "Iteration: 740000\n",
      "Coef: [ 4.95910704 30.02254787]\n",
      "Loss: 28.406113324101554\n",
      "Iteration: 750000\n",
      "Coef: [ 5.02428055 30.02243243]\n",
      "Loss: 28.160727569432012\n",
      "Iteration: 760000\n",
      "Coef: [ 5.08914255 30.02244614]\n",
      "Loss: 27.916978322202684\n",
      "Iteration: 770000\n",
      "Coef: [ 5.15372807 30.02225374]\n",
      "Loss: 27.67617872570891\n",
      "Iteration: 780000\n",
      "Coef: [ 5.21803364 30.02226061]\n",
      "Loss: 27.436908854257375\n",
      "Iteration: 790000\n",
      "Coef: [ 5.28205802 30.0220624 ]\n",
      "Loss: 27.199392997312724\n",
      "Iteration: 800000\n",
      "Coef: [ 5.34583032 30.0219604 ]\n",
      "Loss: 26.96422159218841\n",
      "Iteration: 810000\n",
      "Coef: [ 5.40930209 30.02196892]\n",
      "Loss: 26.731824136418105\n",
      "Iteration: 820000\n",
      "Coef: [ 5.47250097 30.02176803]\n",
      "Loss: 26.500764490805132\n",
      "Iteration: 830000\n",
      "Coef: [ 5.53542347 30.02178311]\n",
      "Loss: 26.27135291751655\n",
      "Iteration: 840000\n",
      "Coef: [ 5.59807354 30.02158692]\n",
      "Loss: 26.043951656567092\n",
      "Iteration: 850000\n",
      "Coef: [ 5.66047682 30.02148482]\n",
      "Loss: 25.818803915503292\n",
      "Iteration: 860000\n",
      "Coef: [ 5.72258377 30.02149259]\n",
      "Loss: 25.5954292390297\n",
      "Iteration: 870000\n",
      "Coef: [ 5.78442602 30.02130409]\n",
      "Loss: 25.374818048765306\n",
      "Iteration: 880000\n",
      "Coef: [ 5.84599814 30.02131215]\n",
      "Loss: 25.155194281322107\n",
      "Iteration: 890000\n",
      "Coef: [ 5.90730347 30.02112531]\n",
      "Loss: 24.937513289093534\n",
      "Iteration: 900000\n",
      "Coef: [ 5.96836701 30.02102312]\n",
      "Loss: 24.721980350321658\n",
      "Iteration: 910000\n",
      "Coef: [ 6.02914068 30.02103324]\n",
      "Loss: 24.508719446463164\n",
      "Iteration: 920000\n",
      "Coef: [ 6.08965532 30.020842  ]\n",
      "Loss: 24.2970417890831\n",
      "Iteration: 930000\n",
      "Coef: [ 6.14990367 30.0208498 ]\n",
      "Loss: 24.086422086419024\n",
      "Iteration: 940000\n",
      "Coef: [ 6.20989503 30.02066408]\n",
      "Loss: 23.878294585094167\n",
      "Iteration: 950000\n",
      "Coef: [ 6.26964603 30.02057517]\n",
      "Loss: 23.67168516636605\n",
      "Iteration: 960000\n",
      "Coef: [ 6.32911508 30.0205804 ]\n",
      "Loss: 23.466950355820792\n",
      "Iteration: 970000\n",
      "Coef: [ 6.38833076 30.02039454]\n",
      "Loss: 23.264852891970477\n",
      "Iteration: 980000\n",
      "Coef: [ 6.44728558 30.02040453]\n",
      "Loss: 23.06324923351432\n",
      "Iteration: 990000\n",
      "Coef: [ 6.505987   30.02022629]\n",
      "Loss: 22.863767511808014\n",
      "Iteration: 1000000\n",
      "Coef: [ 6.56445706 30.02012446]\n",
      "Loss: 22.666228353142877\n",
      "Iteration: 1010000\n",
      "Coef: [ 6.62264784 30.02013612]\n",
      "Loss: 22.47000091011129\n",
      "Iteration: 1020000\n",
      "Coef: [ 6.68059242 30.01995801]\n",
      "Loss: 22.276461739518048\n",
      "Iteration: 1030000\n",
      "Coef: [ 6.73828182 30.01996619]\n",
      "Loss: 22.083472263699356\n",
      "Iteration: 1040000\n",
      "Coef: [ 6.7957233  30.01979145]\n",
      "Loss: 21.89248161900508\n",
      "Iteration: 1050000\n",
      "Coef: [ 6.85293616 30.01970136]\n",
      "Loss: 21.703169871694037\n",
      "Iteration: 1060000\n",
      "Coef: [ 6.90987952 30.01970848]\n",
      "Loss: 21.51605399085894\n",
      "Iteration: 1070000\n",
      "Coef: [ 6.96657832 30.01953334]\n",
      "Loss: 21.329969615835648\n",
      "Iteration: 1080000\n",
      "Coef: [ 7.02302947 30.01953501]\n",
      "Loss: 21.145262261423312\n",
      "Iteration: 1090000\n",
      "Coef: [ 7.07923784 30.01936737]\n",
      "Loss: 20.96243030991387\n",
      "Iteration: 1100000\n",
      "Coef: [ 7.13522263 30.01927821]\n",
      "Loss: 20.781180722459258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1110000\n",
      "Coef: [ 7.1909436  30.01928708]\n",
      "Loss: 20.602087195168163\n",
      "Iteration: 1120000\n",
      "Coef: [ 7.24642505 30.01910928]\n",
      "Loss: 20.424005823392807\n",
      "Iteration: 1130000\n",
      "Coef: [ 7.30166448 30.01912081]\n",
      "Loss: 20.247105499893504\n",
      "Iteration: 1140000\n",
      "Coef: [ 7.35666654 30.01894578]\n",
      "Loss: 20.072025323265972\n",
      "Iteration: 1150000\n",
      "Coef: [ 7.41144754 30.01886663]\n",
      "Loss: 19.898323052800876\n",
      "Iteration: 1160000\n",
      "Coef: [ 7.46597269 30.01887076]\n",
      "Loss: 19.726776016822647\n",
      "Iteration: 1170000\n",
      "Coef: [ 7.52026327 30.01870035]\n",
      "Loss: 19.556300043341817\n",
      "Iteration: 1180000\n",
      "Coef: [ 7.57431469 30.01870301]\n",
      "Loss: 19.38679424476352\n",
      "Iteration: 1190000\n",
      "Coef: [ 7.62813586 30.01854439]\n",
      "Loss: 19.219217898191197\n",
      "Iteration: 1200000\n",
      "Coef: [ 7.68174298 30.01845658]\n",
      "Loss: 19.053077947882922\n",
      "Iteration: 1210000\n",
      "Coef: [ 7.73509554 30.01846362]\n",
      "Loss: 18.888248241191036\n",
      "Iteration: 1220000\n",
      "Coef: [ 7.78822065 30.01829923]\n",
      "Loss: 18.72549739852908\n",
      "Iteration: 1230000\n",
      "Coef: [ 7.84111212 30.01830101]\n",
      "Loss: 18.563197049490476\n",
      "Iteration: 1240000\n",
      "Coef: [ 7.89377799 30.01814554]\n",
      "Loss: 18.402761046339997\n",
      "Iteration: 1250000\n",
      "Coef: [ 7.94623421 30.0180571 ]\n",
      "Loss: 18.243718312729197\n",
      "Iteration: 1260000\n",
      "Coef: [ 7.9984413  30.01807203]\n",
      "Loss: 18.0864351158199\n",
      "Iteration: 1270000\n",
      "Coef: [ 8.05042405 30.01790856]\n",
      "Loss: 17.929927426324674\n",
      "Iteration: 1280000\n",
      "Coef: [ 8.10217991 30.01790835]\n",
      "Loss: 17.77460657687239\n",
      "Iteration: 1290000\n",
      "Coef: [ 8.15371521 30.01775404]\n",
      "Loss: 17.621015942233917\n",
      "Iteration: 1300000\n",
      "Coef: [ 8.20504355 30.01767571]\n",
      "Loss: 17.46860060851818\n",
      "Iteration: 1310000\n",
      "Coef: [ 8.25613024 30.01767868]\n",
      "Loss: 17.3175169858974\n",
      "Iteration: 1320000\n",
      "Coef: [ 8.30699891 30.01751888]\n",
      "Loss: 17.168409821281262\n",
      "Iteration: 1330000\n",
      "Coef: [ 8.35764374 30.01752955]\n",
      "Loss: 17.019635684042296\n",
      "Iteration: 1340000\n",
      "Coef: [ 8.40807088 30.01737359]\n",
      "Loss: 16.872430433790573\n",
      "Iteration: 1350000\n",
      "Coef: [ 8.45829739 30.01729566]\n",
      "Loss: 16.726512095020286\n",
      "Iteration: 1360000\n",
      "Coef: [ 8.50828727 30.01730159]\n",
      "Loss: 16.582283027422687\n",
      "Iteration: 1370000\n",
      "Coef: [ 8.55806234 30.01714835]\n",
      "Loss: 16.438877065658595\n",
      "Iteration: 1380000\n",
      "Coef: [ 8.60762002 30.01714955]\n",
      "Loss: 16.296532251654195\n",
      "Iteration: 1390000\n",
      "Coef: [ 8.65696462 30.01700267]\n",
      "Loss: 16.155623689327534\n",
      "Iteration: 1400000\n",
      "Coef: [ 8.70611303 30.01692561]\n",
      "Loss: 16.01592457799697\n",
      "Iteration: 1410000\n",
      "Coef: [ 8.75503006 30.01692907]\n",
      "Loss: 15.877430451753531\n",
      "Iteration: 1420000\n",
      "Coef: [ 8.8037366  30.01677965]\n",
      "Loss: 15.740539247418214\n",
      "Iteration: 1430000\n",
      "Coef: [ 8.85223064 30.01678218]\n",
      "Loss: 15.604243393621957\n",
      "Iteration: 1440000\n",
      "Coef: [ 8.90051629 30.01663679]\n",
      "Loss: 15.46931527422008\n",
      "Iteration: 1450000\n",
      "Coef: [ 8.94860981 30.01656075]\n",
      "Loss: 15.33555559176767\n",
      "Iteration: 1460000\n",
      "Coef: [ 8.99647675 30.01656828]\n",
      "Loss: 15.20337685863515\n",
      "Iteration: 1470000\n",
      "Coef: [ 9.04413777 30.01641519]\n",
      "Loss: 15.071982347050264\n",
      "Iteration: 1480000\n",
      "Coef: [ 9.09158904 30.01641946]\n",
      "Loss: 14.941297507291225\n",
      "Iteration: 1490000\n",
      "Coef: [ 9.13883987 30.0162724 ]\n",
      "Loss: 14.812280625562106\n",
      "Iteration: 1500000\n",
      "Coef: [ 9.18589929 30.01620529]\n",
      "Loss: 14.684070518902223\n",
      "Iteration: 1510000\n",
      "Coef: [ 9.23273899 30.01621236]\n",
      "Loss: 14.557499286667774\n",
      "Iteration: 1520000\n",
      "Coef: [ 9.279377   30.01606206]\n",
      "Loss: 14.431714689194518\n",
      "Iteration: 1530000\n",
      "Coef: [ 9.32580961 30.01606879]\n",
      "Loss: 14.306596646864168\n",
      "Iteration: 1540000\n",
      "Coef: [ 9.37204457 30.01592847]\n",
      "Loss: 14.182923686971797\n",
      "Iteration: 1550000\n",
      "Coef: [ 9.41809363 30.01586049]\n",
      "Loss: 14.060224185329764\n",
      "Iteration: 1560000\n",
      "Coef: [ 9.46392772 30.01586306]\n",
      "Loss: 13.93902589226971\n",
      "Iteration: 1570000\n",
      "Coef: [ 9.50956468 30.0157176 ]\n",
      "Loss: 13.818612469625206\n",
      "Iteration: 1580000\n",
      "Coef: [ 9.55500067 30.01572404]\n",
      "Loss: 13.698828385901395\n",
      "Iteration: 1590000\n",
      "Coef: [ 9.60024304 30.01558447]\n",
      "Loss: 13.580438708119077\n",
      "Iteration: 1600000\n",
      "Coef: [ 9.64530384 30.01551801]\n",
      "Loss: 13.462939342627406\n",
      "Iteration: 1610000\n",
      "Coef: [ 9.69015391 30.01552623]\n",
      "Loss: 13.347000470544959\n",
      "Iteration: 1620000\n",
      "Coef: [ 9.73480946 30.01538247]\n",
      "Loss: 13.231498126708493\n",
      "Iteration: 1630000\n",
      "Coef: [ 9.77927037 30.01538452]\n",
      "Loss: 13.116838605129715\n",
      "Iteration: 1640000\n",
      "Coef: [ 9.82354143 30.01525022]\n",
      "Loss: 13.003507611547255\n",
      "Iteration: 1650000\n",
      "Coef: [ 9.86763476 30.01518313]\n",
      "Loss: 12.891028002515709\n",
      "Iteration: 1660000\n",
      "Coef: [ 9.91152059 30.0151876 ]\n",
      "Loss: 12.779530599633103\n",
      "Iteration: 1670000\n",
      "Coef: [ 9.95521915 30.01504847]\n",
      "Loss: 12.669509602415545\n",
      "Iteration: 1680000\n",
      "Coef: [ 9.99872379 30.0150528 ]\n",
      "Loss: 12.559586880005114\n",
      "Iteration: 1690000\n",
      "Coef: [10.04204476 30.01492444]\n",
      "Loss: 12.45106560007011\n",
      "Iteration: 1700000\n",
      "Coef: [10.08519152 30.01485745]\n",
      "Loss: 12.343388394409764\n",
      "Iteration: 1710000\n",
      "Coef: [10.12813524 30.0148625 ]\n",
      "Loss: 12.236934225950685\n",
      "Iteration: 1720000\n",
      "Coef: [10.17089425 30.01473111]\n",
      "Loss: 12.131118032929416\n",
      "Iteration: 1730000\n",
      "Coef: [10.21346659 30.01473214]\n",
      "Loss: 12.02607398318328\n",
      "Iteration: 1740000\n",
      "Coef: [10.25585735 30.01459817]\n",
      "Loss: 11.922218820004302\n",
      "Iteration: 1750000\n",
      "Coef: [10.2980766  30.01454036]\n",
      "Loss: 11.818996118402161\n",
      "Iteration: 1760000\n",
      "Coef: [10.34009857 30.01454232]\n",
      "Loss: 11.716795166266252\n",
      "Iteration: 1770000\n",
      "Coef: [10.38193971 30.01441488]\n",
      "Loss: 11.61576196027403\n",
      "Iteration: 1780000\n",
      "Coef: [10.42359828 30.01441636]\n",
      "Loss: 11.515191664156136\n",
      "Iteration: 1790000\n",
      "Coef: [10.46507765 30.01429097]\n",
      "Loss: 11.415636779675287\n",
      "Iteration: 1800000\n",
      "Coef: [10.50639043 30.01423185]\n",
      "Loss: 11.316865258967994\n",
      "Iteration: 1810000\n",
      "Coef: [10.54751176 30.01423463]\n",
      "Loss: 11.219431387265876\n",
      "Iteration: 1820000\n",
      "Coef: [10.58845472 30.01409903]\n",
      "Loss: 11.122477169492521\n",
      "Iteration: 1830000\n",
      "Coef: [10.62921744 30.01410719]\n",
      "Loss: 11.026010852900722\n",
      "Iteration: 1840000\n",
      "Coef: [10.6698064  30.01398258]\n",
      "Loss: 10.930701907841838\n",
      "Iteration: 1850000\n",
      "Coef: [10.71023237 30.01392407]\n",
      "Loss: 10.83612495174792\n",
      "Iteration: 1860000\n",
      "Coef: [10.75046946 30.01392585]\n",
      "Loss: 10.742710715280158\n",
      "Iteration: 1870000\n",
      "Coef: [10.79053351 30.01379857]\n",
      "Loss: 10.649908512958486\n",
      "Iteration: 1880000\n",
      "Coef: [10.83042128 30.01380319]\n",
      "Loss: 10.557586900838285\n",
      "Iteration: 1890000\n",
      "Coef: [10.87013893 30.0136824 ]\n",
      "Loss: 10.46634455810672\n",
      "Iteration: 1900000\n",
      "Coef: [10.90969704 30.01362382]\n",
      "Loss: 10.375799591548326\n",
      "Iteration: 1910000\n",
      "Coef: [10.94907057 30.01362833]\n",
      "Loss: 10.286383374355891\n",
      "Iteration: 1920000\n",
      "Coef: [10.98827321 30.01350689]\n",
      "Loss: 10.19736337066497\n",
      "Iteration: 1930000\n",
      "Coef: [11.02730621 30.01350975]\n",
      "Loss: 10.109129634815845\n",
      "Iteration: 1940000\n",
      "Coef: [11.06617106 30.01338287]\n",
      "Loss: 10.021805566468988\n",
      "Iteration: 1950000\n",
      "Coef: [11.10487858 30.0133317 ]\n",
      "Loss: 9.935012985670093\n",
      "Iteration: 1960000\n",
      "Coef: [11.14340686 30.01333656]\n",
      "Loss: 9.849424192452677\n",
      "Iteration: 1970000\n",
      "Coef: [11.18176784 30.01321434]\n",
      "Loss: 9.764221660118297\n",
      "Iteration: 1980000\n",
      "Coef: [11.21996149 30.01321714]\n",
      "Loss: 9.67963419116379\n",
      "Iteration: 1990000\n",
      "Coef: [11.2579923  30.01309874]\n",
      "Loss: 9.596009257648136\n",
      "Iteration: 2000000\n",
      "Coef: [11.29586874 30.01304641]\n",
      "Loss: 9.512947667688454\n",
      "Iteration: 2010000\n",
      "Coef: [11.33356977 30.0130512 ]\n",
      "Loss: 9.431033970544036\n",
      "Iteration: 2020000\n",
      "Coef: [11.37110746 30.01292935]\n",
      "Loss: 9.349451571192043\n",
      "Iteration: 2030000\n",
      "Coef: [11.40848129 30.01293513]\n",
      "Loss: 9.26845487696498\n",
      "Iteration: 2040000\n",
      "Coef: [11.44569565 30.0128137 ]\n",
      "Loss: 9.188413995528219\n",
      "Iteration: 2050000\n",
      "Coef: [11.48275799 30.0127696 ]\n",
      "Loss: 9.108792239375736\n",
      "Iteration: 2060000\n",
      "Coef: [11.51965    30.01276708]\n",
      "Loss: 9.030072037933635\n",
      "Iteration: 2070000\n",
      "Coef: [11.55638192 30.01265489]\n",
      "Loss: 8.95219416110365\n",
      "Iteration: 2080000\n",
      "Coef: [11.5929535  30.01265545]\n",
      "Loss: 8.874682211414559\n",
      "Iteration: 2090000\n",
      "Coef: [11.62936911 30.01254048]\n",
      "Loss: 8.798041050486784\n",
      "Iteration: 2100000\n",
      "Coef: [11.66563569 30.01249533]\n",
      "Loss: 8.721833954347373\n",
      "Iteration: 2110000\n",
      "Coef: [11.70173575 30.01249406]\n",
      "Loss: 8.646680368555177\n",
      "Iteration: 2120000\n",
      "Coef: [11.73767903 30.01238027]\n",
      "Loss: 8.571954246817391\n",
      "Iteration: 2130000\n",
      "Coef: [11.77346548 30.01238762]\n",
      "Loss: 8.497730941695488\n",
      "Iteration: 2140000\n",
      "Coef: [11.8090981  30.01227248]\n",
      "Loss: 8.424265379489446\n",
      "Iteration: 2150000\n",
      "Coef: [11.84458626 30.01222759]\n",
      "Loss: 8.351310356271922\n",
      "Iteration: 2160000\n",
      "Coef: [11.87991128 30.01222657]\n",
      "Loss: 8.279373843964146\n",
      "Iteration: 2170000\n",
      "Coef: [11.91508304 30.01211272]\n",
      "Loss: 8.207842976127843\n",
      "Iteration: 2180000\n",
      "Coef: [11.95010018 30.01211758]\n",
      "Loss: 8.136668707323473\n",
      "Iteration: 2190000\n",
      "Coef: [11.98496935 30.01200691]\n",
      "Loss: 8.066415630378845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2200000\n",
      "Coef: [12.01969568 30.01196254]\n",
      "Loss: 7.9965498174646426\n",
      "Iteration: 2210000\n",
      "Coef: [12.05426246 30.01196773]\n",
      "Loss: 7.92775219649323\n",
      "Iteration: 2220000\n",
      "Coef: [12.08867801 30.01185461]\n",
      "Loss: 7.8591108621273\n",
      "Iteration: 2230000\n",
      "Coef: [12.12294337 30.01185705]\n",
      "Loss: 7.791002233866338\n",
      "Iteration: 2240000\n",
      "Coef: [12.15706392 30.01174785]\n",
      "Loss: 7.723757407300112\n",
      "Iteration: 2250000\n",
      "Coef: [12.19104336 30.01170827]\n",
      "Loss: 7.656822689877082\n",
      "Iteration: 2260000\n",
      "Coef: [12.22486814 30.01170849]\n",
      "Loss: 7.590902535019036\n",
      "Iteration: 2270000\n",
      "Coef: [12.25854494 30.0116014 ]\n",
      "Loss: 7.525212490921802\n",
      "Iteration: 2280000\n",
      "Coef: [12.29207477 30.01160207]\n",
      "Loss: 7.460020992562451\n",
      "Iteration: 2290000\n",
      "Coef: [12.32546279 30.01149448]\n",
      "Loss: 7.395655218457241\n",
      "Iteration: 2300000\n",
      "Coef: [12.35871298 30.01145605]\n",
      "Loss: 7.331552780932515\n",
      "Iteration: 2310000\n",
      "Coef: [12.39181178 30.01145854]\n",
      "Loss: 7.268465318899305\n",
      "Iteration: 2320000\n",
      "Coef: [12.42476438 30.01135525]\n",
      "Loss: 7.2054697216920625\n",
      "Iteration: 2330000\n",
      "Coef: [12.45757565 30.01135615]\n",
      "Loss: 7.143148907468168\n",
      "Iteration: 2340000\n",
      "Coef: [12.49024575 30.0112491 ]\n",
      "Loss: 7.081452793102169\n",
      "Iteration: 2350000\n",
      "Coef: [12.52278232 30.01121092]\n",
      "Loss: 7.020088722898082\n",
      "Iteration: 2360000\n",
      "Coef: [12.5551705  30.01121297]\n",
      "Loss: 6.95969941013345\n",
      "Iteration: 2370000\n",
      "Coef: [12.58741597 30.01111129]\n",
      "Loss: 6.899369486146727\n",
      "Iteration: 2380000\n",
      "Coef: [12.61952285 30.01111361]\n",
      "Loss: 6.839712906103185\n",
      "Iteration: 2390000\n",
      "Coef: [12.65149057 30.01101185]\n",
      "Loss: 6.780562462355153\n",
      "Iteration: 2400000\n",
      "Coef: [12.68332979 30.01096769]\n",
      "Loss: 6.721879626211558\n",
      "Iteration: 2410000\n",
      "Coef: [12.71502163 30.01097004]\n",
      "Loss: 6.663981217703049\n",
      "Iteration: 2420000\n",
      "Coef: [12.74657467 30.01087276]\n",
      "Loss: 6.60627064377018\n",
      "Iteration: 2430000\n",
      "Coef: [12.77799255 30.01087479]\n",
      "Loss: 6.549145586561054\n",
      "Iteration: 2440000\n",
      "Coef: [12.80927394 30.01077418]\n",
      "Loss: 6.4925260343760804\n",
      "Iteration: 2450000\n",
      "Coef: [12.84042857 30.01073522]\n",
      "Loss: 6.436300979869881\n",
      "Iteration: 2460000\n",
      "Coef: [12.87144115 30.01073785]\n",
      "Loss: 6.380968891583152\n",
      "Iteration: 2470000\n",
      "Coef: [12.90231682 30.01063514]\n",
      "Loss: 6.325701989639175\n",
      "Iteration: 2480000\n",
      "Coef: [12.93305896 30.01064189]\n",
      "Loss: 6.270934964026953\n",
      "Iteration: 2490000\n",
      "Coef: [12.96366904 30.01054224]\n",
      "Loss: 6.2167188816628505\n",
      "Iteration: 2500000\n",
      "Coef: [12.99415497 30.01050392]\n",
      "Loss: 6.16288015199437\n",
      "Iteration: 2510000\n",
      "Coef: [13.0245008  30.01050322]\n",
      "Loss: 6.109791919010968\n",
      "Iteration: 2520000\n",
      "Coef: [13.05471381 30.01041042]\n",
      "Loss: 6.056906402038328\n",
      "Iteration: 2530000\n",
      "Coef: [13.08479612 30.01041036]\n",
      "Loss: 6.004492438132288\n",
      "Iteration: 2540000\n",
      "Coef: [13.11474901 30.01031784]\n",
      "Loss: 5.952597718846291\n",
      "Iteration: 2550000\n",
      "Coef: [13.14458039 30.01027872]\n",
      "Loss: 5.9010676602219565\n",
      "Iteration: 2560000\n",
      "Coef: [13.17427486 30.01027787]\n",
      "Loss: 5.8502397570325675\n",
      "Iteration: 2570000\n",
      "Coef: [13.2038393  30.01018591]\n",
      "Loss: 5.799614124082525\n",
      "Iteration: 2580000\n",
      "Coef: [13.23327587 30.01018845]\n",
      "Loss: 5.749430582767568\n",
      "Iteration: 2590000\n",
      "Coef: [13.26258587 30.01009396]\n",
      "Loss: 5.699746423789718\n",
      "Iteration: 2600000\n",
      "Coef: [13.29177695 30.01005582]\n",
      "Loss: 5.650392955334576\n",
      "Iteration: 2610000\n",
      "Coef: [13.32083395 30.01006092]\n",
      "Loss: 5.601798441381282\n",
      "Iteration: 2620000\n",
      "Coef: [13.34976253 30.00996716]\n",
      "Loss: 5.553236336933366\n",
      "Iteration: 2630000\n",
      "Coef: [13.37856718 30.00997064]\n",
      "Loss: 5.505196618065137\n",
      "Iteration: 2640000\n",
      "Coef: [13.407248   30.00987518]\n",
      "Loss: 5.457635549530579\n",
      "Iteration: 2650000\n",
      "Coef: [13.43581141 30.00984203]\n",
      "Loss: 5.410340788581911\n",
      "Iteration: 2660000\n",
      "Coef: [13.46424465 30.00984316]\n",
      "Loss: 5.363781698427738\n",
      "Iteration: 2670000\n",
      "Coef: [13.49255246 30.00975483]\n",
      "Loss: 5.317297053759673\n",
      "Iteration: 2680000\n",
      "Coef: [13.52073872 30.00975585]\n",
      "Loss: 5.271316209614103\n",
      "Iteration: 2690000\n",
      "Coef: [13.54880379 30.00966258]\n",
      "Loss: 5.225792071698291\n",
      "Iteration: 2700000\n",
      "Coef: [13.57675401 30.00962955]\n",
      "Loss: 5.180506822581277\n",
      "Iteration: 2710000\n",
      "Coef: [13.60457692 30.00963407]\n",
      "Loss: 5.135971689840165\n",
      "Iteration: 2720000\n",
      "Coef: [13.63227713 30.00954306]\n",
      "Loss: 5.0914451956437\n",
      "Iteration: 2730000\n",
      "Coef: [13.65985741 30.00954453]\n",
      "Loss: 5.047358862327582\n",
      "Iteration: 2740000\n",
      "Coef: [13.68732018 30.00945745]\n",
      "Loss: 5.003762290594516\n",
      "Iteration: 2750000\n",
      "Coef: [13.71467046 30.00942401]\n",
      "Loss: 4.9604215274904755\n",
      "Iteration: 2760000\n",
      "Coef: [13.74189614 30.00942627]\n",
      "Loss: 4.917762393618632\n",
      "Iteration: 2770000\n",
      "Coef: [13.76900068 30.00934226]\n",
      "Loss: 4.875089459575279\n",
      "Iteration: 2780000\n",
      "Coef: [13.79598998 30.00934011]\n",
      "Loss: 4.8329425031740705\n",
      "Iteration: 2790000\n",
      "Coef: [13.8228631  30.00925208]\n",
      "Loss: 4.791219010835066\n",
      "Iteration: 2800000\n",
      "Coef: [13.84962623 30.00921929]\n",
      "Loss: 4.749707474108431\n",
      "Iteration: 2810000\n",
      "Coef: [13.8762664  30.00922317]\n",
      "Loss: 4.708830572739655\n",
      "Iteration: 2820000\n",
      "Coef: [13.90278909 30.00914148]\n",
      "Loss: 4.6679890347935755\n",
      "Iteration: 2830000\n",
      "Coef: [13.92919894 30.00914083]\n",
      "Loss: 4.627644864186821\n",
      "Iteration: 2840000\n",
      "Coef: [13.95549431 30.00905675]\n",
      "Loss: 4.587642675973757\n",
      "Iteration: 2850000\n",
      "Coef: [13.981683   30.00902346]\n",
      "Loss: 4.5479188365679\n",
      "Iteration: 2860000\n",
      "Coef: [14.0077524  30.00902756]\n",
      "Loss: 4.508845130281375\n",
      "Iteration: 2870000\n",
      "Coef: [14.03370581 30.00894302]\n",
      "Loss: 4.469713230725533\n",
      "Iteration: 2880000\n",
      "Coef: [14.05954786 30.0089431 ]\n",
      "Loss: 4.431036823775824\n",
      "Iteration: 2890000\n",
      "Coef: [14.08527879 30.00886336]\n",
      "Loss: 4.392739772605263\n",
      "Iteration: 2900000\n",
      "Coef: [14.11090521 30.0088296 ]\n",
      "Loss: 4.3547150282782106\n",
      "Iteration: 2910000\n",
      "Coef: [14.13641403 30.00882992]\n",
      "Loss: 4.317218175183794\n",
      "Iteration: 2920000\n",
      "Coef: [14.16181028 30.00875322]\n",
      "Loss: 4.279801678261719\n",
      "Iteration: 2930000\n",
      "Coef: [14.18709862 30.00875306]\n",
      "Loss: 4.242819385302153\n",
      "Iteration: 2940000\n",
      "Coef: [14.21227716 30.0086697 ]\n",
      "Loss: 4.206161151768623\n",
      "Iteration: 2950000\n",
      "Coef: [14.23735356 30.0086372 ]\n",
      "Loss: 4.169734397078513\n",
      "Iteration: 2960000\n",
      "Coef: [14.2623148  30.00864464]\n",
      "Loss: 4.133906018134293\n",
      "Iteration: 2970000\n",
      "Coef: [14.28716502 30.00856527]\n",
      "Loss: 4.097987119752876\n",
      "Iteration: 2980000\n",
      "Coef: [14.31191049 30.0085659 ]\n",
      "Loss: 4.06258472729707\n",
      "Iteration: 2990000\n",
      "Coef: [14.33654773 30.00848717]\n",
      "Loss: 4.027439489689201\n",
      "Iteration: 3000000\n",
      "Coef: [14.36108586 30.0084542 ]\n",
      "Loss: 3.99258157822445\n",
      "Iteration: 3010000\n",
      "Coef: [14.38551123 30.00845688]\n",
      "Loss: 3.958241953293059\n",
      "Iteration: 3020000\n",
      "Coef: [14.40982809 30.00838258]\n",
      "Loss: 3.9238820414450104\n",
      "Iteration: 3030000\n",
      "Coef: [14.43404228 30.00838152]\n",
      "Loss: 3.8899926170429637\n",
      "Iteration: 3040000\n",
      "Coef: [14.45815057 30.00830433]\n",
      "Loss: 3.8563512028167968\n",
      "Iteration: 3050000\n",
      "Coef: [14.48216203 30.00827193]\n",
      "Loss: 3.8229726756581943\n",
      "Iteration: 3060000\n",
      "Coef: [14.50606309 30.008277  ]\n",
      "Loss: 3.790123442418211\n",
      "Iteration: 3070000\n",
      "Coef: [14.52985783 30.00820039]\n",
      "Loss: 3.7572132382832244\n",
      "Iteration: 3080000\n",
      "Coef: [14.55355145 30.00820038]\n",
      "Loss: 3.7247254251383373\n",
      "Iteration: 3090000\n",
      "Coef: [14.5771422  30.00812642]\n",
      "Loss: 3.6925222931576123\n",
      "Iteration: 3100000\n",
      "Coef: [14.60063815 30.00809383]\n",
      "Loss: 3.660568274226824\n",
      "Iteration: 3110000\n",
      "Coef: [14.62402624 30.00810018]\n",
      "Loss: 3.6291308409366927\n",
      "Iteration: 3120000\n",
      "Coef: [14.64731023 30.00802326]\n",
      "Loss: 3.597612349610074\n",
      "Iteration: 3130000\n",
      "Coef: [14.67049519 30.00802636]\n",
      "Loss: 3.566513452219537\n",
      "Iteration: 3140000\n",
      "Coef: [14.69357955 30.00794911]\n",
      "Loss: 3.535681940874396\n",
      "Iteration: 3150000\n",
      "Coef: [14.71657025 30.00792066]\n",
      "Loss: 3.5050570322145314\n",
      "Iteration: 3160000\n",
      "Coef: [14.7394553 30.0079224]\n",
      "Loss: 3.4748813468047888\n",
      "Iteration: 3170000\n",
      "Coef: [14.76223955 30.00785358]\n",
      "Loss: 3.444748940427465\n",
      "Iteration: 3180000\n",
      "Coef: [14.78492682 30.00785165]\n",
      "Loss: 3.41497689221177\n",
      "Iteration: 3190000\n",
      "Coef: [14.80751561 30.00778022]\n",
      "Loss: 3.3854634748553787\n",
      "Iteration: 3200000\n",
      "Coef: [14.83001365 30.00774806]\n",
      "Loss: 3.3561695761891026\n",
      "Iteration: 3210000\n",
      "Coef: [14.8524075  30.00775584]\n",
      "Loss: 3.327330244693586\n",
      "Iteration: 3220000\n",
      "Coef: [14.87470173 30.00768471]\n",
      "Loss: 3.2984121900121512\n",
      "Iteration: 3230000\n",
      "Coef: [14.89690206 30.0076836 ]\n",
      "Loss: 3.2699071841789387\n",
      "Iteration: 3240000\n",
      "Coef: [14.91900604 30.00761231]\n",
      "Loss: 3.241649637251765\n",
      "Iteration: 3250000\n",
      "Coef: [14.94102034 30.00758406]\n",
      "Loss: 3.2135803486116754\n",
      "Iteration: 3260000\n",
      "Coef: [14.96293352 30.00758675]\n",
      "Loss: 3.1859287277661643\n",
      "Iteration: 3270000\n",
      "Coef: [14.98475005 30.00751808]\n",
      "Loss: 3.1583065542858377\n",
      "Iteration: 3280000\n",
      "Coef: [15.0064729  30.00751794]\n",
      "Loss: 3.1309889233444013\n",
      "Iteration: 3290000\n",
      "Coef: [15.02810238 30.00744891]\n",
      "Loss: 3.1039376355831485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3300000\n",
      "Coef: [15.04964408 30.00742065]\n",
      "Loss: 3.0770642929680965\n",
      "Iteration: 3310000\n",
      "Coef: [15.07108685 30.0074254 ]\n",
      "Loss: 3.050612895412962\n",
      "Iteration: 3320000\n",
      "Coef: [15.09243423 30.00735799]\n",
      "Loss: 3.0241215125051593\n",
      "Iteration: 3330000\n",
      "Coef: [15.11369166 30.00735874]\n",
      "Loss: 2.997999474012364\n",
      "Iteration: 3340000\n",
      "Coef: [15.13485605 30.00728992]\n",
      "Loss: 2.972068661436087\n",
      "Iteration: 3350000\n",
      "Coef: [15.15593536 30.00726169]\n",
      "Loss: 2.9463429541459165\n",
      "Iteration: 3360000\n",
      "Coef: [15.17691769 30.007267  ]\n",
      "Loss: 2.9210369617417045\n",
      "Iteration: 3370000\n",
      "Coef: [15.19780682 30.0071988 ]\n",
      "Loss: 2.895663996793338\n",
      "Iteration: 3380000\n",
      "Coef: [15.21860717 30.00719913]\n",
      "Loss: 2.8706238094704077\n",
      "Iteration: 3390000\n",
      "Coef: [15.23931722 30.00713434]\n",
      "Loss: 2.8458027367191825\n",
      "Iteration: 3400000\n",
      "Coef: [15.259944   30.00710596]\n",
      "Loss: 2.8211763609150915\n",
      "Iteration: 3410000\n",
      "Coef: [15.28047609 30.00711039]\n",
      "Loss: 2.7969345249057476\n",
      "Iteration: 3420000\n",
      "Coef: [15.30091679 30.00704406]\n",
      "Loss: 2.772652478513958\n",
      "Iteration: 3430000\n",
      "Coef: [15.32127056 30.00704562]\n",
      "Loss: 2.7486841646768254\n",
      "Iteration: 3440000\n",
      "Coef: [15.3415353  30.00698296]\n",
      "Loss: 2.7248957859446272\n",
      "Iteration: 3450000\n",
      "Coef: [15.36172011 30.0069517 ]\n",
      "Loss: 2.7013358164372403\n",
      "Iteration: 3460000\n",
      "Coef: [15.38181075 30.00695628]\n",
      "Loss: 2.678089967911321\n",
      "Iteration: 3470000\n",
      "Coef: [15.40181271 30.00689359]\n",
      "Loss: 2.6548569914766813\n",
      "Iteration: 3480000\n",
      "Coef: [15.42172967 30.00689347]\n",
      "Loss: 2.631906769794465\n",
      "Iteration: 3490000\n",
      "Coef: [15.44156013 30.0068299 ]\n",
      "Loss: 2.609158222962047\n",
      "Iteration: 3500000\n",
      "Coef: [15.46131091 30.00680219]\n",
      "Loss: 2.5865790925993615\n",
      "Iteration: 3510000\n",
      "Coef: [15.48097029 30.00680772]\n",
      "Loss: 2.564332841064283\n",
      "Iteration: 3520000\n",
      "Coef: [15.50054293 30.00674469]\n",
      "Loss: 2.542082084397188\n",
      "Iteration: 3530000\n",
      "Coef: [15.52003231 30.00674722]\n",
      "Loss: 2.520113833669701\n",
      "Iteration: 3540000\n",
      "Coef: [15.53943646 30.0066849 ]\n",
      "Loss: 2.4983042087506884\n",
      "Iteration: 3550000\n",
      "Coef: [15.55876331 30.00665734]\n",
      "Loss: 2.4766900924370905\n",
      "Iteration: 3560000\n",
      "Coef: [15.57800059 30.00666118]\n",
      "Loss: 2.455388347468034\n",
      "Iteration: 3570000\n",
      "Coef: [15.59715308 30.00659969]\n",
      "Loss: 2.4340911316314244\n",
      "Iteration: 3580000\n",
      "Coef: [15.61622408 30.00660323]\n",
      "Loss: 2.4130626906339034\n",
      "Iteration: 3590000\n",
      "Coef: [15.63521091 30.00654282]\n",
      "Loss: 2.39216247752811\n",
      "Iteration: 3600000\n",
      "Coef: [15.65412281 30.00651501]\n",
      "Loss: 2.3714731419155584\n",
      "Iteration: 3610000\n",
      "Coef: [15.67294709 30.00651826]\n",
      "Loss: 2.351080549940394\n",
      "Iteration: 3620000\n",
      "Coef: [15.69168841 30.00645727]\n",
      "Loss: 2.3306939755411924\n",
      "Iteration: 3630000\n",
      "Coef: [15.71034935 30.00645933]\n",
      "Loss: 2.310532641833084\n",
      "Iteration: 3640000\n",
      "Coef: [15.72892923 30.00640034]\n",
      "Loss: 2.2905515916753303\n",
      "Iteration: 3650000\n",
      "Coef: [15.74743521 30.00637298]\n",
      "Loss: 2.270738625966258\n",
      "Iteration: 3660000\n",
      "Coef: [15.76585488 30.00637699]\n",
      "Loss: 2.251182044656767\n",
      "Iteration: 3670000\n",
      "Coef: [15.78419401 30.00631971]\n",
      "Loss: 2.2316706057801974\n",
      "Iteration: 3680000\n",
      "Coef: [15.80245436 30.00632004]\n",
      "Loss: 2.212371840582597\n",
      "Iteration: 3690000\n",
      "Coef: [15.82063544 30.00626327]\n",
      "Loss: 2.193242144314081\n",
      "Iteration: 3700000\n",
      "Coef: [15.83874423 30.00623633]\n",
      "Loss: 2.1742721798078146\n",
      "Iteration: 3710000\n",
      "Coef: [15.85676843 30.00624076]\n",
      "Loss: 2.1555573177273155\n",
      "Iteration: 3720000\n",
      "Coef: [15.87471382 30.00618266]\n",
      "Loss: 2.1368781581386456\n",
      "Iteration: 3730000\n",
      "Coef: [15.89258228 30.00618582]\n",
      "Loss: 2.118397614114687\n",
      "Iteration: 3740000\n",
      "Coef: [15.91037248 30.00613013]\n",
      "Loss: 2.1000608233738363\n",
      "Iteration: 3750000\n",
      "Coef: [15.92809241 30.00610269]\n",
      "Loss: 2.0819037398202274\n",
      "Iteration: 3760000\n",
      "Coef: [15.9457298  30.00610649]\n",
      "Loss: 2.063980817178084\n",
      "Iteration: 3770000\n",
      "Coef: [15.96328931 30.00605238]\n",
      "Loss: 2.0460767508021087\n",
      "Iteration: 3780000\n",
      "Coef: [15.98077477 30.00605425]\n",
      "Loss: 2.0284146361311794\n",
      "Iteration: 3790000\n",
      "Coef: [15.99818315 30.00599726]\n",
      "Loss: 2.010853103054136\n",
      "Iteration: 3800000\n",
      "Coef: [16.0155221  30.00597302]\n",
      "Loss: 1.993454581489318\n",
      "Iteration: 3810000\n",
      "Coef: [16.0327808  30.00597468]\n",
      "Loss: 1.9762893376325155\n",
      "Iteration: 3820000\n",
      "Coef: [16.04996403 30.00591999]\n",
      "Loss: 1.9591770067461796\n",
      "Iteration: 3830000\n",
      "Coef: [16.06707351 30.00592454]\n",
      "Loss: 1.9422460405750135\n",
      "Iteration: 3840000\n",
      "Coef: [16.08410749 30.00587025]\n",
      "Loss: 1.925418752303996\n",
      "Iteration: 3850000\n",
      "Coef: [16.10107493 30.0058437 ]\n",
      "Loss: 1.9087731839528133\n",
      "Iteration: 3860000\n",
      "Coef: [16.11796316 30.0058482 ]\n",
      "Loss: 1.8923576110761846\n",
      "Iteration: 3870000\n",
      "Coef: [16.13477689 30.00579362]\n",
      "Loss: 1.875940506447523\n",
      "Iteration: 3880000\n",
      "Coef: [16.1515191  30.00579697]\n",
      "Loss: 1.8597324964877464\n",
      "Iteration: 3890000\n",
      "Coef: [16.16818746 30.00574425]\n",
      "Loss: 1.8436230103834268\n",
      "Iteration: 3900000\n",
      "Coef: [16.18479056 30.00571727]\n",
      "Loss: 1.8276892423353672\n",
      "Iteration: 3910000\n",
      "Coef: [16.20131571 30.0057207 ]\n",
      "Loss: 1.811940539307695\n",
      "Iteration: 3920000\n",
      "Coef: [16.21776855 30.0056705 ]\n",
      "Loss: 1.7962362590532563\n",
      "Iteration: 3930000\n",
      "Coef: [16.23415134 30.00567151]\n",
      "Loss: 1.7807196320689889\n",
      "Iteration: 3940000\n",
      "Coef: [16.25046189 30.00562122]\n",
      "Loss: 1.7653009797781962\n",
      "Iteration: 3950000\n",
      "Coef: [16.26670859 30.00559452]\n",
      "Loss: 1.7500455605790044\n",
      "Iteration: 3960000\n",
      "Coef: [16.28287898 30.00559848]\n",
      "Loss: 1.7349735229585843\n",
      "Iteration: 3970000\n",
      "Coef: [16.29897863 30.00554779]\n",
      "Loss: 1.7199365030475815\n",
      "Iteration: 3980000\n",
      "Coef: [16.31500981 30.00555106]\n",
      "Loss: 1.7050816204427977\n",
      "Iteration: 3990000\n",
      "Coef: [16.3309756  30.00552344]\n",
      "Loss: 1.690303254033972\n",
      "Iteration: 4000000\n",
      "Coef: [16.34686765 30.0054754 ]\n",
      "Loss: 1.6756961041748881\n",
      "Iteration: 4010000\n",
      "Coef: [16.36269092 30.00547769]\n",
      "Loss: 1.6612611587569075\n",
      "Iteration: 4020000\n",
      "Coef: [16.37844496 30.00542873]\n",
      "Loss: 1.6468697686638927\n",
      "Iteration: 4030000\n",
      "Coef: [16.39413141 30.0054295 ]\n",
      "Loss: 1.6326289773057243\n",
      "Iteration: 4040000\n",
      "Coef: [16.40975505 30.00540566]\n",
      "Loss: 1.6184990264544286\n",
      "Iteration: 4050000\n",
      "Coef: [16.42530593 30.0053564 ]\n",
      "Loss: 1.6045153880454341\n",
      "Iteration: 4060000\n",
      "Coef: [16.44078895 30.00535929]\n",
      "Loss: 1.5906786577666503\n",
      "Iteration: 4070000\n",
      "Coef: [16.45620488 30.00531277]\n",
      "Loss: 1.5769028259795441\n",
      "Iteration: 4080000\n",
      "Coef: [16.47155515 30.00531563]\n",
      "Loss: 1.5632916075795074\n",
      "Iteration: 4090000\n",
      "Coef: [16.48683717 30.00526695]\n",
      "Loss: 1.5497427455259578\n",
      "Iteration: 4100000\n",
      "Coef: [16.50205933 30.0052433 ]\n",
      "Loss: 1.536345072375603\n",
      "Iteration: 4110000\n",
      "Coef: [16.51721053 30.00524548]\n",
      "Loss: 1.5231179218822024\n",
      "Iteration: 4120000\n",
      "Coef: [16.53229547 30.00519689]\n",
      "Loss: 1.5099276616753556\n",
      "Iteration: 4130000\n",
      "Coef: [16.54731565 30.00520132]\n",
      "Loss: 1.4968787298664723\n",
      "Iteration: 4140000\n",
      "Coef: [16.56226962 30.00515358]\n",
      "Loss: 1.4839081699202743\n",
      "Iteration: 4150000\n",
      "Coef: [16.57716509 30.00513039]\n",
      "Loss: 1.4710795807687438\n",
      "Iteration: 4160000\n",
      "Coef: [16.59199108 30.00513355]\n",
      "Loss: 1.4584213338900702\n",
      "Iteration: 4170000\n",
      "Coef: [16.60675171 30.00508695]\n",
      "Loss: 1.4457700793703259\n",
      "Iteration: 4180000\n",
      "Coef: [16.62144949 30.005088  ]\n",
      "Loss: 1.4332767128692998\n",
      "Iteration: 4190000\n",
      "Coef: [16.63608791 30.00506423]\n",
      "Loss: 1.4208650097816065\n",
      "Iteration: 4200000\n",
      "Coef: [16.65065817 30.00502081]\n",
      "Loss: 1.408583362680913\n",
      "Iteration: 4210000\n",
      "Coef: [16.66516587 30.00502319]\n",
      "Loss: 1.3964632271928525\n",
      "Iteration: 4220000\n",
      "Coef: [16.67960968 30.00497764]\n",
      "Loss: 1.38435160632173\n",
      "Iteration: 4230000\n",
      "Coef: [16.69399195 30.00497934]\n",
      "Loss: 1.3723923232063637\n",
      "Iteration: 4240000\n",
      "Coef: [16.70831082 30.00493482]\n",
      "Loss: 1.3605069790154192\n",
      "Iteration: 4250000\n",
      "Coef: [16.72257364 30.00491188]\n",
      "Loss: 1.3487480347839145\n",
      "Iteration: 4260000\n",
      "Coef: [16.73676939 30.00491441]\n",
      "Loss: 1.337128397178613\n",
      "Iteration: 4270000\n",
      "Coef: [16.75090313 30.00487104]\n",
      "Loss: 1.3255398528484184\n",
      "Iteration: 4280000\n",
      "Coef: [16.76497676 30.00487195]\n",
      "Loss: 1.31408718592761\n",
      "Iteration: 4290000\n",
      "Coef: [16.77899349 30.00484972]\n",
      "Loss: 1.3027092443492763\n",
      "Iteration: 4300000\n",
      "Coef: [16.79294493 30.00480615]\n",
      "Loss: 1.291451557668694\n",
      "Iteration: 4310000\n",
      "Coef: [16.80683596 30.00480953]\n",
      "Loss: 1.280331326844107\n",
      "Iteration: 4320000\n",
      "Coef: [16.82066628 30.00476554]\n",
      "Loss: 1.2692345754090089\n",
      "Iteration: 4330000\n",
      "Coef: [16.83443722 30.00476671]\n",
      "Loss: 1.258258406125622\n",
      "Iteration: 4340000\n",
      "Coef: [16.84815302 30.00474555]\n",
      "Loss: 1.2473676826690558\n",
      "Iteration: 4350000\n",
      "Coef: [16.86180492 30.00470236]\n",
      "Loss: 1.2365907049470113\n",
      "Iteration: 4360000\n",
      "Coef: [16.8753973  30.00470464]\n",
      "Loss: 1.2259240744416082\n",
      "Iteration: 4370000\n",
      "Coef: [16.88893121 30.00466199]\n",
      "Loss: 1.2153245136048012\n",
      "Iteration: 4380000\n",
      "Coef: [16.90240649 30.00466643]\n",
      "Loss: 1.2048185893041001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4390000\n",
      "Coef: [16.91582739 30.00464347]\n",
      "Loss: 1.1943768057334587\n",
      "Iteration: 4400000\n",
      "Coef: [16.9291863  30.00460155]\n",
      "Loss: 1.1840575355514054\n",
      "Iteration: 4410000\n",
      "Coef: [16.94248696 30.00460356]\n",
      "Loss: 1.173843885478301\n",
      "Iteration: 4420000\n",
      "Coef: [16.95573039 30.00456175]\n",
      "Loss: 1.1636963151377757\n",
      "Iteration: 4430000\n",
      "Coef: [16.96891646 30.00456651]\n",
      "Loss: 1.153637386489028\n",
      "Iteration: 4440000\n",
      "Coef: [16.9820493 30.0045441]\n",
      "Loss: 1.1436383636504213\n",
      "Iteration: 4450000\n",
      "Coef: [16.99512095 30.00450418]\n",
      "Loss: 1.1337516422211091\n",
      "Iteration: 4460000\n",
      "Coef: [17.00813605 30.00450394]\n",
      "Loss: 1.1239700775252537\n",
      "Iteration: 4470000\n",
      "Coef: [17.02109523 30.00446452]\n",
      "Loss: 1.1142547782562147\n",
      "Iteration: 4480000\n",
      "Coef: [17.03399828 30.00446789]\n",
      "Loss: 1.1046246701161462\n",
      "Iteration: 4490000\n",
      "Coef: [17.04684914 30.00444667]\n",
      "Loss: 1.0950548844588193\n",
      "Iteration: 4500000\n",
      "Coef: [17.05964028 30.00440739]\n",
      "Loss: 1.0855878522675995\n",
      "Iteration: 4510000\n",
      "Coef: [17.07237596 30.00440775]\n",
      "Loss: 1.076225804764797\n",
      "Iteration: 4520000\n",
      "Coef: [17.08505647 30.00436974]\n",
      "Loss: 1.0669117848515492\n",
      "Iteration: 4530000\n",
      "Coef: [17.09768255 30.00437096]\n",
      "Loss: 1.0576919890112055\n",
      "Iteration: 4540000\n",
      "Coef: [17.11025758 30.00435058]\n",
      "Loss: 1.0485328896973691\n",
      "Iteration: 4550000\n",
      "Coef: [17.12277454 30.00431061]\n",
      "Loss: 1.0394772833950707\n",
      "Iteration: 4560000\n",
      "Coef: [17.1352364  30.00431325]\n",
      "Loss: 1.0305067796763878\n",
      "Iteration: 4570000\n",
      "Coef: [17.1476447  30.00427541]\n",
      "Loss: 1.0215904874262065\n",
      "Iteration: 4580000\n",
      "Coef: [17.15999969 30.0042784 ]\n",
      "Loss: 1.0127669364955036\n",
      "Iteration: 4590000\n",
      "Coef: [17.17230027 30.00423853]\n",
      "Loss: 1.0039930844830045\n",
      "Iteration: 4600000\n",
      "Coef: [17.18455264 30.00421862]\n",
      "Loss: 0.9953163154820995\n",
      "Iteration: 4610000\n",
      "Coef: [17.19674696 30.00422059]\n",
      "Loss: 0.9867284263919888\n",
      "Iteration: 4620000\n",
      "Coef: [17.20888891 30.00418339]\n",
      "Loss: 0.9781927979397466\n",
      "Iteration: 4630000\n",
      "Coef: [17.22097827 30.00418471]\n",
      "Loss: 0.9697322680624467\n",
      "Iteration: 4640000\n",
      "Coef: [17.23301919 30.00416593]\n",
      "Loss: 0.9613384554171869\n",
      "Iteration: 4650000\n",
      "Coef: [17.24500415 30.004129  ]\n",
      "Loss: 0.953030315971747\n",
      "Iteration: 4660000\n",
      "Coef: [17.25693676 30.0041292 ]\n",
      "Loss: 0.9448044298462791\n",
      "Iteration: 4670000\n",
      "Coef: [17.26881806 30.00409406]\n",
      "Loss: 0.9366342043687313\n",
      "Iteration: 4680000\n",
      "Coef: [17.28064792 30.00409464]\n",
      "Loss: 0.9285350173603042\n",
      "Iteration: 4690000\n",
      "Coef: [17.29243039 30.00407642]\n",
      "Loss: 0.9204987534861084\n",
      "Iteration: 4700000\n",
      "Coef: [17.30415802 30.00403982]\n",
      "Loss: 0.9125454161404589\n",
      "Iteration: 4710000\n",
      "Coef: [17.31583444 30.00404148]\n",
      "Loss: 0.9046744184290445\n",
      "Iteration: 4720000\n",
      "Coef: [17.32746072 30.00400495]\n",
      "Loss: 0.8968517509766855\n",
      "Iteration: 4730000\n",
      "Coef: [17.33903665 30.00400829]\n",
      "Loss: 0.8890973035834888\n",
      "Iteration: 4740000\n",
      "Coef: [17.35056577 30.00398874]\n",
      "Loss: 0.8813938280345076\n",
      "Iteration: 4750000\n",
      "Coef: [17.36204169 30.00395313]\n",
      "Loss: 0.8737785808957657\n",
      "Iteration: 4760000\n",
      "Coef: [17.37346749 30.00395484]\n",
      "Loss: 0.8662430868075107\n",
      "Iteration: 4770000\n",
      "Coef: [17.38484417 30.00391839]\n",
      "Loss: 0.858755552995934\n",
      "Iteration: 4780000\n",
      "Coef: [17.39617111 30.00392143]\n",
      "Loss: 0.8513225441574575\n",
      "Iteration: 4790000\n",
      "Coef: [17.407449   30.00388573]\n",
      "Loss: 0.8439550044404297\n",
      "Iteration: 4800000\n",
      "Coef: [17.41868234 30.00386847]\n",
      "Loss: 0.8366582434272939\n",
      "Iteration: 4810000\n",
      "Coef: [17.42986244 30.00386838]\n",
      "Loss: 0.8294327018917316\n",
      "Iteration: 4820000\n",
      "Coef: [17.4409949  30.00383566]\n",
      "Loss: 0.8222651754977952\n",
      "Iteration: 4830000\n",
      "Coef: [17.4520792  30.00383766]\n",
      "Loss: 0.8151589110022343\n",
      "Iteration: 4840000\n",
      "Coef: [17.46311861 30.00381972]\n",
      "Loss: 0.8080992340870065\n",
      "Iteration: 4850000\n",
      "Coef: [17.47410708 30.00378377]\n",
      "Loss: 0.8011207672553222\n",
      "Iteration: 4860000\n",
      "Coef: [17.4850468  30.00378519]\n",
      "Loss: 0.7941961115063907\n",
      "Iteration: 4870000\n",
      "Coef: [17.49594031 30.00375326]\n",
      "Loss: 0.787334121108984\n",
      "Iteration: 4880000\n",
      "Coef: [17.50678665 30.00375572]\n",
      "Loss: 0.7805318990253209\n",
      "Iteration: 4890000\n",
      "Coef: [17.51758914 30.00373816]\n",
      "Loss: 0.7737709697712467\n",
      "Iteration: 4900000\n",
      "Coef: [17.52834141 30.00370413]\n",
      "Loss: 0.7670826254039821\n",
      "Iteration: 4910000\n",
      "Coef: [17.5390467 30.0037044]\n",
      "Loss: 0.7604600748382871\n",
      "Iteration: 4920000\n",
      "Coef: [17.54970637 30.00367179]\n",
      "Loss: 0.753891803659991\n",
      "Iteration: 4930000\n",
      "Coef: [17.56031948 30.0036744 ]\n",
      "Loss: 0.747369944678004\n",
      "Iteration: 4940000\n",
      "Coef: [17.57089007 30.00365761]\n",
      "Loss: 0.7408989206928268\n",
      "Iteration: 4950000\n",
      "Coef: [17.5814115  30.00362443]\n",
      "Loss: 0.734496007491782\n",
      "Iteration: 4960000\n",
      "Coef: [17.59188696 30.00362536]\n",
      "Loss: 0.7281574752546193\n",
      "Iteration: 4970000\n",
      "Coef: [17.6023174  30.00359375]\n",
      "Loss: 0.7218604625784698\n",
      "Iteration: 4980000\n",
      "Coef: [17.61270271 30.00359484]\n",
      "Loss: 0.7156172556455924\n",
      "Iteration: 4990000\n",
      "Coef: [17.62304637 30.00357878]\n",
      "Loss: 0.7094234715998009\n",
      "Iteration: 5000000\n",
      "Coef: [17.6333419  30.00354641]\n",
      "Loss: 0.7032939444049977\n",
      "Iteration: 5010000\n",
      "Coef: [17.64359252 30.00354788]\n",
      "Loss: 0.6972264917387825\n",
      "Iteration: 5020000\n",
      "Coef: [17.65379912 30.00351628]\n",
      "Loss: 0.6911961877209594\n",
      "Iteration: 5030000\n",
      "Coef: [17.66396151 30.00351824]\n",
      "Loss: 0.6852190553043624\n",
      "Iteration: 5040000\n",
      "Coef: [17.67408316 30.00350261]\n",
      "Loss: 0.6792875637593986\n",
      "Iteration: 5050000\n",
      "Coef: [17.68415771 30.00346939]\n",
      "Loss: 0.67341920532978\n",
      "Iteration: 5060000\n",
      "Coef: [17.69418795 30.00347098]\n",
      "Loss: 0.6676022804587638\n",
      "Iteration: 5070000\n",
      "Coef: [17.7041754  30.00344103]\n",
      "Loss: 0.6618314630227283\n",
      "Iteration: 5080000\n",
      "Coef: [17.71411964 30.00344273]\n",
      "Loss: 0.6561098095491174\n",
      "Iteration: 5090000\n",
      "Coef: [17.72402033 30.00341113]\n",
      "Loss: 0.6504315457062697\n",
      "Iteration: 5100000\n",
      "Coef: [17.73388192 30.00339603]\n",
      "Loss: 0.644807962130518\n",
      "Iteration: 5110000\n",
      "Coef: [17.7436972 30.0033973]\n",
      "Loss: 0.6392465734550277\n",
      "Iteration: 5120000\n",
      "Coef: [17.75347028 30.00336604]\n",
      "Loss: 0.633721705686944\n",
      "Iteration: 5130000\n",
      "Coef: [17.76320068 30.00336853]\n",
      "Loss: 0.6282357858407686\n",
      "Iteration: 5140000\n",
      "Coef: [17.77288888 30.00333804]\n",
      "Loss: 0.6227995092263128\n",
      "Iteration: 5150000\n",
      "Coef: [17.78253878 30.00332302]\n",
      "Loss: 0.6174155334053719\n",
      "Iteration: 5160000\n",
      "Coef: [17.79214299 30.00332327]\n",
      "Loss: 0.6120837167743899\n",
      "Iteration: 5170000\n",
      "Coef: [17.80170628 30.00329474]\n",
      "Loss: 0.6067947044778728\n",
      "Iteration: 5180000\n",
      "Coef: [17.81122776 30.00329573]\n",
      "Loss: 0.6015453022956639\n",
      "Iteration: 5190000\n",
      "Coef: [17.82071148 30.00328187]\n",
      "Loss: 0.5963413054381095\n",
      "Iteration: 5200000\n",
      "Coef: [17.83015073 30.00325156]\n",
      "Loss: 0.5911869539981462\n",
      "Iteration: 5210000\n",
      "Coef: [17.83954884 30.00325197]\n",
      "Loss: 0.5860815224531227\n",
      "Iteration: 5220000\n",
      "Coef: [17.84890683 30.0032236 ]\n",
      "Loss: 0.5810189867193277\n",
      "Iteration: 5230000\n",
      "Coef: [17.85822397 30.00322535]\n",
      "Loss: 0.575991995536135\n",
      "Iteration: 5240000\n",
      "Coef: [17.86750073 30.00319594]\n",
      "Loss: 0.5710089342654615\n",
      "Iteration: 5250000\n",
      "Coef: [17.87674075 30.00318088]\n",
      "Loss: 0.5660745093669549\n",
      "Iteration: 5260000\n",
      "Coef: [17.88593674 30.00318186]\n",
      "Loss: 0.5611822247886263\n",
      "Iteration: 5270000\n",
      "Coef: [17.8950939  30.00315477]\n",
      "Loss: 0.55633423158038\n",
      "Iteration: 5280000\n",
      "Coef: [17.90421105 30.00315593]\n",
      "Loss: 0.5515220621443081\n",
      "Iteration: 5290000\n",
      "Coef: [17.91328866 30.00312716]\n",
      "Loss: 0.5467518228528686\n",
      "Iteration: 5300000\n",
      "Coef: [17.92233002 30.00311395]\n",
      "Loss: 0.5420230848383585\n",
      "Iteration: 5310000\n",
      "Coef: [17.93132892 30.00311404]\n",
      "Loss: 0.5373446294790702\n",
      "Iteration: 5320000\n",
      "Coef: [17.94028946 30.00308584]\n",
      "Loss: 0.5327062261356901\n",
      "Iteration: 5330000\n",
      "Coef: [17.94921059 30.00308788]\n",
      "Loss: 0.5280913162376832\n",
      "Iteration: 5340000\n",
      "Coef: [17.95809336 30.0030602 ]\n",
      "Loss: 0.5235242155838136\n",
      "Iteration: 5350000\n",
      "Coef: [17.96694064 30.00304705]\n",
      "Loss: 0.518997017286826\n",
      "Iteration: 5360000\n",
      "Coef: [17.97574639 30.00304732]\n",
      "Loss: 0.5145179008148392\n",
      "Iteration: 5370000\n",
      "Coef: [17.9845146  30.00301925]\n",
      "Loss: 0.5100776262659786\n",
      "Iteration: 5380000\n",
      "Coef: [17.99324388 30.00302083]\n",
      "Loss: 0.5056544763758624\n",
      "Iteration: 5390000\n",
      "Coef: [18.00193913 30.00300892]\n",
      "Loss: 0.5012827958860431\n",
      "Iteration: 5400000\n",
      "Coef: [18.01059362 30.00298023]\n",
      "Loss: 0.4969524800981713\n",
      "Iteration: 5410000\n",
      "Coef: [18.01921002 30.00298196]\n",
      "Loss: 0.492660608146612\n",
      "Iteration: 5420000\n",
      "Coef: [18.02778969 30.00295568]\n",
      "Loss: 0.488402147890816\n",
      "Iteration: 5430000\n",
      "Coef: [18.03633192 30.00295638]\n",
      "Loss: 0.48417462938683903\n",
      "Iteration: 5440000\n",
      "Coef: [18.04483741 30.00293001]\n",
      "Loss: 0.47998889765406605\n",
      "Iteration: 5450000\n",
      "Coef: [18.05330892 30.0029169 ]\n",
      "Loss: 0.4758393429370096\n",
      "Iteration: 5460000\n",
      "Coef: [18.06174035 30.00291766]\n",
      "Loss: 0.4717300770391112\n",
      "Iteration: 5470000\n",
      "Coef: [18.07013584 30.00289227]\n",
      "Loss: 0.46765368104675253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5480000\n",
      "Coef: [18.07849468 30.00289315]\n",
      "Loss: 0.4636067976988376\n",
      "Iteration: 5490000\n",
      "Coef: [18.08682035 30.00288067]\n",
      "Loss: 0.459595703492724\n",
      "Iteration: 5500000\n",
      "Coef: [18.09510697 30.00285511]\n",
      "Loss: 0.4556229682634268\n",
      "Iteration: 5510000\n",
      "Coef: [18.10335772 30.00285572]\n",
      "Loss: 0.4516937117445467\n",
      "Iteration: 5520000\n",
      "Coef: [18.11157295 30.00282887]\n",
      "Loss: 0.44779316305397787\n",
      "Iteration: 5530000\n",
      "Coef: [18.11975208 30.00283091]\n",
      "Loss: 0.4439115450872519\n",
      "Iteration: 5540000\n",
      "Coef: [18.12789903 30.00281892]\n",
      "Loss: 0.44007146398340347\n",
      "Iteration: 5550000\n",
      "Coef: [18.13600773 30.00279332]\n",
      "Loss: 0.43626835502436284\n",
      "Iteration: 5560000\n",
      "Coef: [18.14408108 30.00279374]\n",
      "Loss: 0.4325016074075246\n",
      "Iteration: 5570000\n",
      "Coef: [18.15212002 30.00276901]\n",
      "Loss: 0.42876579047418495\n",
      "Iteration: 5580000\n",
      "Coef: [18.16012356 30.00276971]\n",
      "Loss: 0.4250521159182018\n",
      "Iteration: 5590000\n",
      "Coef: [18.16809563 30.00275812]\n",
      "Loss: 0.42137589599841246\n",
      "Iteration: 5600000\n",
      "Coef: [18.1760303  30.00273356]\n",
      "Loss: 0.41773438690051307\n",
      "Iteration: 5610000\n",
      "Coef: [18.18393035 30.00273373]\n",
      "Loss: 0.41412797075075686\n",
      "Iteration: 5620000\n",
      "Coef: [18.19179672 30.00270931]\n",
      "Loss: 0.41055208968713475\n",
      "Iteration: 5630000\n",
      "Coef: [18.19962845 30.00271066]\n",
      "Loss: 0.40699632300590394\n",
      "Iteration: 5640000\n",
      "Coef: [18.2074294  30.00269945]\n",
      "Loss: 0.4034761517296043\n",
      "Iteration: 5650000\n",
      "Coef: [18.21519373 30.002674  ]\n",
      "Loss: 0.3999901488945199\n",
      "Iteration: 5660000\n",
      "Coef: [18.22292421 30.00267595]\n",
      "Loss: 0.3965394866436875\n",
      "Iteration: 5670000\n",
      "Coef: [18.23062144 30.0026513 ]\n",
      "Loss: 0.3931103046134103\n",
      "Iteration: 5680000\n",
      "Coef: [18.23828477 30.00265135]\n",
      "Loss: 0.3897034178373865\n",
      "Iteration: 5690000\n",
      "Coef: [18.24591853 30.00264185]\n",
      "Loss: 0.38633649303889406\n",
      "Iteration: 5700000\n",
      "Coef: [18.25351596 30.00261767]\n",
      "Loss: 0.38299552057475256\n",
      "Iteration: 5710000\n",
      "Coef: [18.26108052 30.00261764]\n",
      "Loss: 0.37968958569423683\n",
      "Iteration: 5720000\n",
      "Coef: [18.26861278 30.00259363]\n",
      "Loss: 0.37641358505633543\n",
      "Iteration: 5730000\n",
      "Coef: [18.27611163 30.00259502]\n",
      "Loss: 0.3731494652438451\n",
      "Iteration: 5740000\n",
      "Coef: [18.28358125 30.00258471]\n",
      "Loss: 0.36992328705399613\n",
      "Iteration: 5750000\n",
      "Coef: [18.29101556 30.00256144]\n",
      "Loss: 0.36672517791432346\n",
      "Iteration: 5760000\n",
      "Coef: [18.2984177  30.00256175]\n",
      "Loss: 0.3635610580548027\n",
      "Iteration: 5770000\n",
      "Coef: [18.30578798 30.00253865]\n",
      "Loss: 0.36041963393948656\n",
      "Iteration: 5780000\n",
      "Coef: [18.31312586 30.00253897]\n",
      "Loss: 0.35729658083123084\n",
      "Iteration: 5790000\n",
      "Coef: [18.32043514 30.00252899]\n",
      "Loss: 0.3542078595298092\n",
      "Iteration: 5800000\n",
      "Coef: [18.32770989 30.0025066 ]\n",
      "Loss: 0.3511457167684644\n",
      "Iteration: 5810000\n",
      "Coef: [18.33495314 30.00250674]\n",
      "Loss: 0.3481162801560201\n",
      "Iteration: 5820000\n",
      "Coef: [18.34216524 30.00248408]\n",
      "Loss: 0.34510856314884514\n",
      "Iteration: 5830000\n",
      "Coef: [18.34934559 30.0024847 ]\n",
      "Loss: 0.34211851372760627\n",
      "Iteration: 5840000\n",
      "Coef: [18.35649795 30.00247528]\n",
      "Loss: 0.33916156979606127\n",
      "Iteration: 5850000\n",
      "Coef: [18.36361652 30.00245195]\n",
      "Loss: 0.336229967961408\n",
      "Iteration: 5860000\n",
      "Coef: [18.370704   30.00245284]\n",
      "Loss: 0.33332729197279326\n",
      "Iteration: 5870000\n",
      "Coef: [18.37776128 30.00243062]\n",
      "Loss: 0.33044820875049324\n",
      "Iteration: 5880000\n",
      "Coef: [18.38478752 30.00243154]\n",
      "Loss: 0.32758516792187725\n",
      "Iteration: 5890000\n",
      "Coef: [18.39178636 30.00242249]\n",
      "Loss: 0.324754090954234\n",
      "Iteration: 5900000\n",
      "Coef: [18.39875185 30.00239995]\n",
      "Loss: 0.32194510769108875\n",
      "Iteration: 5910000\n",
      "Coef: [18.40568747 30.00240083]\n",
      "Loss: 0.3191698507190155\n",
      "Iteration: 5920000\n",
      "Coef: [18.41259329 30.00237764]\n",
      "Loss: 0.31641354185129533\n",
      "Iteration: 5930000\n",
      "Coef: [18.41946843 30.00237914]\n",
      "Loss: 0.3136682470360138\n",
      "Iteration: 5940000\n",
      "Coef: [18.42631702 30.00237043]\n",
      "Loss: 0.3109578361436629\n",
      "Iteration: 5950000\n",
      "Coef: [18.43313303 30.00234844]\n",
      "Loss: 0.3082682029103566\n",
      "Iteration: 5960000\n",
      "Coef: [18.43991953 30.00234828]\n",
      "Loss: 0.3056066364591555\n",
      "Iteration: 5970000\n",
      "Coef: [18.4466771  30.00232752]\n",
      "Loss: 0.30296773870121585\n",
      "Iteration: 5980000\n",
      "Coef: [18.45340491 30.00232848]\n",
      "Loss: 0.30034401882039596\n",
      "Iteration: 5990000\n",
      "Coef: [18.46010622 30.0023191 ]\n",
      "Loss: 0.2977469273527514\n",
      "Iteration: 6000000\n",
      "Coef: [18.46677588 30.00229804]\n",
      "Loss: 0.29517237951958053\n",
      "Iteration: 6010000\n",
      "Coef: [18.47341672 30.00229787]\n",
      "Loss: 0.2926239325537767\n",
      "Iteration: 6020000\n",
      "Coef: [18.48002923 30.00227734]\n",
      "Loss: 0.29009786913828145\n",
      "Iteration: 6030000\n",
      "Coef: [18.48661238 30.00227783]\n",
      "Loss: 0.2875833308992674\n",
      "Iteration: 6040000\n",
      "Coef: [18.4931701  30.00226981]\n",
      "Loss: 0.28509902092359435\n",
      "Iteration: 6050000\n",
      "Coef: [18.49969634 30.00224914]\n",
      "Loss: 0.2826322090178129\n",
      "Iteration: 6060000\n",
      "Coef: [18.50619483 30.00224947]\n",
      "Loss: 0.2801964935847472\n",
      "Iteration: 6070000\n",
      "Coef: [18.51266517 30.0022284 ]\n",
      "Loss: 0.2777741518341734\n",
      "Iteration: 6080000\n",
      "Coef: [18.51910702 30.00222903]\n",
      "Loss: 0.27536647738108067\n",
      "Iteration: 6090000\n",
      "Coef: [18.52552372 30.00222026]\n",
      "Loss: 0.2729860308629747\n",
      "Iteration: 6100000\n",
      "Coef: [18.53191013 30.00220047]\n",
      "Loss: 0.2706260242271672\n",
      "Iteration: 6110000\n",
      "Coef: [18.53826886 30.00220078]\n",
      "Loss: 0.26829162251764993\n",
      "Iteration: 6120000\n",
      "Coef: [18.54460028 30.00218069]\n",
      "Loss: 0.26597326521322473\n",
      "Iteration: 6130000\n",
      "Coef: [18.55090385 30.00218118]\n",
      "Loss: 0.2636684408838328\n",
      "Iteration: 6140000\n",
      "Coef: [18.55718286 30.00217256]\n",
      "Loss: 0.2613890351855495\n",
      "Iteration: 6150000\n",
      "Coef: [18.56343215 30.00215299]\n",
      "Loss: 0.2591297155286323\n",
      "Iteration: 6160000\n",
      "Coef: [18.56965443 30.00215373]\n",
      "Loss: 0.25689485911126686\n",
      "Iteration: 6170000\n",
      "Coef: [18.57584995 30.00213352]\n",
      "Loss: 0.2546754529905707\n",
      "Iteration: 6180000\n",
      "Coef: [18.58201818 30.0021349 ]\n",
      "Loss: 0.2524684878063096\n",
      "Iteration: 6190000\n",
      "Coef: [18.58816012 30.0021153 ]\n",
      "Loss: 0.25028671753059384\n",
      "Iteration: 6200000\n",
      "Coef: [18.59427729 30.00210676]\n",
      "Loss: 0.2481214162320473\n",
      "Iteration: 6210000\n",
      "Coef: [18.600366   30.00210765]\n",
      "Loss: 0.24598216202095013\n",
      "Iteration: 6220000\n",
      "Coef: [18.60642828 30.00208837]\n",
      "Loss: 0.24385408824177243\n",
      "Iteration: 6230000\n",
      "Coef: [18.61246415 30.00208849]\n",
      "Loss: 0.24174196084328417\n",
      "Iteration: 6240000\n",
      "Coef: [18.61847645 30.00208068]\n",
      "Loss: 0.2396528671301562\n",
      "Iteration: 6250000\n",
      "Coef: [18.62446011 30.00206188]\n",
      "Loss: 0.23758023272732184\n",
      "Iteration: 6260000\n",
      "Coef: [18.63041808 30.00206239]\n",
      "Loss: 0.23553237083540907\n",
      "Iteration: 6270000\n",
      "Coef: [18.63635023 30.00204335]\n",
      "Loss: 0.2334953027115266\n",
      "Iteration: 6280000\n",
      "Coef: [18.64225652 30.00204395]\n",
      "Loss: 0.23147293510158345\n",
      "Iteration: 6290000\n",
      "Coef: [18.64813974 30.00203664]\n",
      "Loss: 0.2294731198072354\n",
      "Iteration: 6300000\n",
      "Coef: [18.65399475 30.00201788]\n",
      "Loss: 0.22748705234908384\n",
      "Iteration: 6310000\n",
      "Coef: [18.65982488 30.00201773]\n",
      "Loss: 0.22552506677654738\n",
      "Iteration: 6320000\n",
      "Coef: [18.66562992 30.00199876]\n",
      "Loss: 0.22357846864187714\n",
      "Iteration: 6330000\n",
      "Coef: [18.67140922 30.00199988]\n",
      "Loss: 0.22163914674066476\n",
      "Iteration: 6340000\n",
      "Coef: [18.67716617 30.00199275]\n",
      "Loss: 0.21972435580654692\n",
      "Iteration: 6350000\n",
      "Coef: [18.6828955  30.00197457]\n",
      "Loss: 0.21782293004570621\n",
      "Iteration: 6360000\n",
      "Coef: [18.68860047 30.00197456]\n",
      "Loss: 0.21594486080881892\n",
      "Iteration: 6370000\n",
      "Coef: [18.69428069 30.00195656]\n",
      "Loss: 0.21407796674485235\n",
      "Iteration: 6380000\n",
      "Coef: [18.69993612 30.00195746]\n",
      "Loss: 0.21222453343835948\n",
      "Iteration: 6390000\n",
      "Coef: [18.70556925 30.00194982]\n",
      "Loss: 0.2103898272708643\n",
      "Iteration: 6400000\n",
      "Coef: [18.71117561 30.0019322 ]\n",
      "Loss: 0.20856938103099532\n",
      "Iteration: 6410000\n",
      "Coef: [18.7167581  30.00193233]\n",
      "Loss: 0.2067717060588457\n",
      "Iteration: 6420000\n",
      "Coef: [18.72231637 30.00191411]\n",
      "Loss: 0.20498496901788882\n",
      "Iteration: 6430000\n",
      "Coef: [18.72785019 30.00191508]\n",
      "Loss: 0.2032081713813629\n",
      "Iteration: 6440000\n",
      "Coef: [18.73336244 30.00190751]\n",
      "Loss: 0.2014513970479091\n",
      "Iteration: 6450000\n",
      "Coef: [18.73884845 30.00189091]\n",
      "Loss: 0.19970874281088793\n",
      "Iteration: 6460000\n",
      "Coef: [18.74431112 30.00189067]\n",
      "Loss: 0.19798705680753348\n",
      "Iteration: 6470000\n",
      "Coef: [18.7497501  30.00187314]\n",
      "Loss: 0.196276355645454\n",
      "Iteration: 6480000\n",
      "Coef: [18.75516515 30.00187389]\n",
      "Loss: 0.19457533246693592\n",
      "Iteration: 6490000\n",
      "Coef: [18.76055905 30.00186671]\n",
      "Loss: 0.19289357983541866\n",
      "Iteration: 6500000\n",
      "Coef: [18.7659273 30.0018501]\n",
      "Loss: 0.19122496691520716\n",
      "Iteration: 6510000\n",
      "Coef: [18.7712725  30.00184969]\n",
      "Loss: 0.18957494280131126\n",
      "Iteration: 6520000\n",
      "Coef: [18.77659471 30.00183317]\n",
      "Loss: 0.18793742495235427\n",
      "Iteration: 6530000\n",
      "Coef: [18.78189352 30.0018336 ]\n",
      "Loss: 0.18630931293207806\n",
      "Iteration: 6540000\n",
      "Coef: [18.78717164 30.00182669]\n",
      "Loss: 0.18469919012530872\n",
      "Iteration: 6550000\n",
      "Coef: [18.79242464 30.00181015]\n",
      "Loss: 0.18310165422168356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6560000\n",
      "Coef: [18.79765511 30.00181026]\n",
      "Loss: 0.18152232025345888\n",
      "Iteration: 6570000\n",
      "Coef: [18.80286309 30.00179337]\n",
      "Loss: 0.17995478409822988\n",
      "Iteration: 6580000\n",
      "Coef: [18.80804814 30.00179477]\n",
      "Loss: 0.17839554187603365\n",
      "Iteration: 6590000\n",
      "Coef: [18.81321277 30.00178728]\n",
      "Loss: 0.17685256887923406\n",
      "Iteration: 6600000\n",
      "Coef: [18.818353   30.00177128]\n",
      "Loss: 0.175327680696032\n",
      "Iteration: 6610000\n",
      "Coef: [18.8234712 30.0017715]\n",
      "Loss: 0.17381125960705884\n",
      "Iteration: 6620000\n",
      "Coef: [18.82856719 30.00175554]\n",
      "Loss: 0.17230802325858194\n",
      "Iteration: 6630000\n",
      "Coef: [18.83364097 30.00175567]\n",
      "Loss: 0.17081594373592204\n",
      "Iteration: 6640000\n",
      "Coef: [18.8386949  30.00174941]\n",
      "Loss: 0.16934026977896818\n",
      "Iteration: 6650000\n",
      "Coef: [18.84372462 30.00173354]\n",
      "Loss: 0.16787476898480283\n",
      "Iteration: 6660000\n",
      "Coef: [18.84873294 30.00173332]\n",
      "Loss: 0.16642698134404227\n",
      "Iteration: 6670000\n",
      "Coef: [18.85371952 30.00171774]\n",
      "Loss: 0.16498832554971224\n",
      "Iteration: 6680000\n",
      "Coef: [18.85868436 30.00171828]\n",
      "Loss: 0.1635598979627377\n",
      "Iteration: 6690000\n",
      "Coef: [18.86362984 30.00171223]\n",
      "Loss: 0.16214699694817064\n",
      "Iteration: 6700000\n",
      "Coef: [18.86855159 30.00169592]\n",
      "Loss: 0.16074800994832206\n",
      "Iteration: 6710000\n",
      "Coef: [18.87345241 30.00169661]\n",
      "Loss: 0.15935846102608764\n",
      "Iteration: 6720000\n",
      "Coef: [18.87833197 30.00168026]\n",
      "Loss: 0.1579809955541035\n",
      "Iteration: 6730000\n",
      "Coef: [18.88319006 30.00168122]\n",
      "Loss: 0.15661127231895183\n",
      "Iteration: 6740000\n",
      "Coef: [18.88802917 30.00167458]\n",
      "Loss: 0.15525739770445252\n",
      "Iteration: 6750000\n",
      "Coef: [18.89284528 30.00166011]\n",
      "Loss: 0.15391425983919338\n",
      "Iteration: 6760000\n",
      "Coef: [18.89764091 30.0016596 ]\n",
      "Loss: 0.152586803287371\n",
      "Iteration: 6770000\n",
      "Coef: [18.90241573 30.00164474]\n",
      "Loss: 0.1512680917622293\n",
      "Iteration: 6780000\n",
      "Coef: [18.90716971 30.00164552]\n",
      "Loss: 0.1499588047355728\n",
      "Iteration: 6790000\n",
      "Coef: [18.91190495 30.00163921]\n",
      "Loss: 0.14866256652642929\n",
      "Iteration: 6800000\n",
      "Coef: [18.91661767 30.00162386]\n",
      "Loss: 0.14738038563410372\n",
      "Iteration: 6810000\n",
      "Coef: [18.92131017 30.00162404]\n",
      "Loss: 0.14610481103786965\n",
      "Iteration: 6820000\n",
      "Coef: [18.92598249 30.0016092 ]\n",
      "Loss: 0.14484251553297647\n",
      "Iteration: 6830000\n",
      "Coef: [18.93063425 30.00160977]\n",
      "Loss: 0.14358756813069173\n",
      "Iteration: 6840000\n",
      "Coef: [18.93526784 30.00160361]\n",
      "Loss: 0.14234655004305596\n",
      "Iteration: 6850000\n",
      "Coef: [18.93987941 30.00158924]\n",
      "Loss: 0.14111851152703042\n",
      "Iteration: 6860000\n",
      "Coef: [18.94447135 30.00158981]\n",
      "Loss: 0.13989995049883272\n",
      "Iteration: 6870000\n",
      "Coef: [18.9490432  30.00157464]\n",
      "Loss: 0.13868933985745358\n",
      "Iteration: 6880000\n",
      "Coef: [18.95359508 30.00157539]\n",
      "Loss: 0.13748800081026558\n",
      "Iteration: 6890000\n",
      "Coef: [18.95812921 30.00156955]\n",
      "Loss: 0.1362999167361472\n",
      "Iteration: 6900000\n",
      "Coef: [18.96264161 30.00155536]\n",
      "Loss: 0.13512017355600942\n",
      "Iteration: 6910000\n",
      "Coef: [18.96713498 30.00155548]\n",
      "Loss: 0.13395613353038385\n",
      "Iteration: 6920000\n",
      "Coef: [18.9716087  30.00154096]\n",
      "Loss: 0.13279724834242565\n",
      "Iteration: 6930000\n",
      "Coef: [18.9760629  30.00154148]\n",
      "Loss: 0.13164710419213377\n",
      "Iteration: 6940000\n",
      "Coef: [18.98049968 30.00153599]\n",
      "Loss: 0.1305098378137526\n",
      "Iteration: 6950000\n",
      "Coef: [18.98491521 30.00152178]\n",
      "Loss: 0.12938019775026327\n",
      "Iteration: 6960000\n",
      "Coef: [18.98931196 30.00152169]\n",
      "Loss: 0.1282643093214765\n",
      "Iteration: 6970000\n",
      "Coef: [18.99368963 30.00150805]\n",
      "Loss: 0.12715537075875555\n",
      "Iteration: 6980000\n",
      "Coef: [18.99804821 30.00150834]\n",
      "Loss: 0.12605445572581842\n",
      "Iteration: 6990000\n",
      "Coef: [19.00238977 30.00150292]\n",
      "Loss: 0.12496543281817617\n",
      "Iteration: 7000000\n",
      "Coef: [19.00671053 30.00148907]\n",
      "Loss: 0.12388392400045\n",
      "Iteration: 7010000\n",
      "Coef: [19.01101291 30.0014891 ]\n",
      "Loss: 0.1228156274896093\n",
      "Iteration: 7020000\n",
      "Coef: [19.01529661 30.0014755 ]\n",
      "Loss: 0.12175393547306645\n",
      "Iteration: 7030000\n",
      "Coef: [19.01956163 30.0014762 ]\n",
      "Loss: 0.12069978679997717\n",
      "Iteration: 7040000\n",
      "Coef: [19.02380983 30.00147031]\n",
      "Loss: 0.11965622596783984\n",
      "Iteration: 7050000\n",
      "Coef: [19.02803783 30.00145722]\n",
      "Loss: 0.11862099372506506\n",
      "Iteration: 7060000\n",
      "Coef: [19.03224787 30.00145704]\n",
      "Loss: 0.11759794545339615\n",
      "Iteration: 7070000\n",
      "Coef: [19.03643962 30.00144379]\n",
      "Loss: 0.11658167473335874\n",
      "Iteration: 7080000\n",
      "Coef: [19.04061309 30.00144461]\n",
      "Loss: 0.11557238956249866\n",
      "Iteration: 7090000\n",
      "Coef: [19.0447701  30.00143897]\n",
      "Loss: 0.1145732920793476\n",
      "Iteration: 7100000\n",
      "Coef: [19.04890734 30.00142568]\n",
      "Loss: 0.11358484302575893\n",
      "Iteration: 7110000\n",
      "Coef: [19.053027   30.00142622]\n",
      "Loss: 0.1126034027973763\n",
      "Iteration: 7120000\n",
      "Coef: [19.05712864 30.00141307]\n",
      "Loss: 0.11162843516441172\n",
      "Iteration: 7130000\n",
      "Coef: [19.06121253 30.00141343]\n",
      "Loss: 0.11066239341662992\n",
      "Iteration: 7140000\n",
      "Coef: [19.06528029 30.00140804]\n",
      "Loss: 0.10970594953427991\n",
      "Iteration: 7150000\n",
      "Coef: [19.06932873 30.00139505]\n",
      "Loss: 0.10875959026490889\n",
      "Iteration: 7160000\n",
      "Coef: [19.07335995 30.00139576]\n",
      "Loss: 0.10782026071780132\n",
      "Iteration: 7170000\n",
      "Coef: [19.07737338 30.00138307]\n",
      "Loss: 0.10688559168200565\n",
      "Iteration: 7180000\n",
      "Coef: [19.08136961 30.00138286]\n",
      "Loss: 0.10596093677968957\n",
      "Iteration: 7190000\n",
      "Coef: [19.08535004 30.0013777 ]\n",
      "Loss: 0.10504532017407626\n",
      "Iteration: 7200000\n",
      "Coef: [19.08931158 30.00136508]\n",
      "Loss: 0.10413932392037481\n",
      "Iteration: 7210000\n",
      "Coef: [19.09325613 30.00136518]\n",
      "Loss: 0.10323824721721346\n",
      "Iteration: 7220000\n",
      "Coef: [19.09718356 30.00135323]\n",
      "Loss: 0.10234515121201396\n",
      "Iteration: 7230000\n",
      "Coef: [19.10109399 30.00135341]\n",
      "Loss: 0.1014598366295973\n",
      "Iteration: 7240000\n",
      "Coef: [19.104989   30.00134848]\n",
      "Loss: 0.10058322715035302\n",
      "Iteration: 7250000\n",
      "Coef: [19.10886535 30.00133599]\n",
      "Loss: 0.09971252411819108\n",
      "Iteration: 7260000\n",
      "Coef: [19.11272535 30.00133649]\n",
      "Loss: 0.09885408955630787\n",
      "Iteration: 7270000\n",
      "Coef: [19.11656833 30.00132412]\n",
      "Loss: 0.09799743516982191\n",
      "Iteration: 7280000\n",
      "Coef: [19.1203948 30.0013246]\n",
      "Loss: 0.09715000751465727\n",
      "Iteration: 7290000\n",
      "Coef: [19.12420605 30.00131917]\n",
      "Loss: 0.0963098466757277\n",
      "Iteration: 7300000\n",
      "Coef: [19.12799934 30.00130691]\n",
      "Loss: 0.09547970890124041\n",
      "Iteration: 7310000\n",
      "Coef: [19.13177636 30.00130756]\n",
      "Loss: 0.09465392940182914\n",
      "Iteration: 7320000\n",
      "Coef: [19.13553684 30.00129579]\n",
      "Loss: 0.09383414447432577\n",
      "Iteration: 7330000\n",
      "Coef: [19.13928119 30.00129611]\n",
      "Loss: 0.09302281825035622\n",
      "Iteration: 7340000\n",
      "Coef: [19.14301065 30.00129079]\n",
      "Loss: 0.09221835962992735\n",
      "Iteration: 7350000\n",
      "Coef: [19.14672237 30.00127935]\n",
      "Loss: 0.09142043948799508\n",
      "Iteration: 7360000\n",
      "Coef: [19.15041844 30.00127972]\n",
      "Loss: 0.090633479538077\n",
      "Iteration: 7370000\n",
      "Coef: [19.15409821 30.00126772]\n",
      "Loss: 0.08984831892940211\n",
      "Iteration: 7380000\n",
      "Coef: [19.15776205 30.00126798]\n",
      "Loss: 0.08907061268340709\n",
      "Iteration: 7390000\n",
      "Coef: [19.16141144 30.00126288]\n",
      "Loss: 0.08830054463501441\n",
      "Iteration: 7400000\n",
      "Coef: [19.16504362 30.00125139]\n",
      "Loss: 0.08753966435238889\n",
      "Iteration: 7410000\n",
      "Coef: [19.1686602  30.00125231]\n",
      "Loss: 0.08678336789883989\n",
      "Iteration: 7420000\n",
      "Coef: [19.17226084 30.00124086]\n",
      "Loss: 0.086030779012024\n",
      "Iteration: 7430000\n",
      "Coef: [19.17584617 30.00124101]\n",
      "Loss: 0.08528705205219238\n",
      "Iteration: 7440000\n",
      "Coef: [19.17941722 30.0012362 ]\n",
      "Loss: 0.08454982974800557\n",
      "Iteration: 7450000\n",
      "Coef: [19.18297129 30.00122463]\n",
      "Loss: 0.08382051115977537\n",
      "Iteration: 7460000\n",
      "Coef: [19.18651026 30.00122535]\n",
      "Loss: 0.08309644360571224\n",
      "Iteration: 7470000\n",
      "Coef: [19.1900336  30.00121422]\n",
      "Loss: 0.08237603001384797\n",
      "Iteration: 7480000\n",
      "Coef: [19.19354196 30.00121457]\n",
      "Loss: 0.08166418535640847\n",
      "Iteration: 7490000\n",
      "Coef: [19.19703623 30.00120921]\n",
      "Loss: 0.08095754700711709\n",
      "Iteration: 7500000\n",
      "Coef: [19.20051403 30.00119867]\n",
      "Loss: 0.08025726981231265\n",
      "Iteration: 7510000\n",
      "Coef: [19.20397702 30.00119875]\n",
      "Loss: 0.07956563680460019\n",
      "Iteration: 7520000\n",
      "Coef: [19.20742474 30.00118832]\n",
      "Loss: 0.07887628281693113\n",
      "Iteration: 7530000\n",
      "Coef: [19.2108578  30.00118832]\n",
      "Loss: 0.0781946888596468\n",
      "Iteration: 7540000\n",
      "Coef: [19.21427705 30.00118326]\n",
      "Loss: 0.07751832223881695\n",
      "Iteration: 7550000\n",
      "Coef: [19.21768019 30.00117283]\n",
      "Loss: 0.07684786714215348\n",
      "Iteration: 7560000\n",
      "Coef: [19.22106884 30.00117326]\n",
      "Loss: 0.07618611415161344\n",
      "Iteration: 7570000\n",
      "Coef: [19.22444254 30.00116246]\n",
      "Loss: 0.07552596738312418\n",
      "Iteration: 7580000\n",
      "Coef: [19.22780177 30.00116269]\n",
      "Loss: 0.07487269916509987\n",
      "Iteration: 7590000\n",
      "Coef: [19.23114763 30.00115779]\n",
      "Loss: 0.07422514501702664\n",
      "Iteration: 7600000\n",
      "Coef: [19.23447772 30.00114762]\n",
      "Loss: 0.0735832468407329\n",
      "Iteration: 7610000\n",
      "Coef: [19.23779364 30.00114816]\n",
      "Loss: 0.07294980704858696\n",
      "Iteration: 7620000\n",
      "Coef: [19.24109478 30.00113781]\n",
      "Loss: 0.07231704608845627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7630000\n",
      "Coef: [19.24438202 30.00113809]\n",
      "Loss: 0.07169243277188218\n",
      "Iteration: 7640000\n",
      "Coef: [19.24765606 30.00113342]\n",
      "Loss: 0.0710723918837545\n",
      "Iteration: 7650000\n",
      "Coef: [19.25091454 30.001123  ]\n",
      "Loss: 0.07045728631446607\n",
      "Iteration: 7660000\n",
      "Coef: [19.25415927 30.00112361]\n",
      "Loss: 0.06985101230952585\n",
      "Iteration: 7670000\n",
      "Coef: [19.25738957 30.00111331]\n",
      "Loss: 0.0692449755359827\n",
      "Iteration: 7680000\n",
      "Coef: [19.26060611 30.00111333]\n",
      "Loss: 0.06864639922602854\n",
      "Iteration: 7690000\n",
      "Coef: [19.26380985 30.00110889]\n",
      "Loss: 0.06805293030191761\n",
      "Iteration: 7700000\n",
      "Coef: [19.26699851 30.00109848]\n",
      "Loss: 0.06746658094487716\n",
      "Iteration: 7710000\n",
      "Coef: [19.27017347 30.00109946]\n",
      "Loss: 0.06688355365227162\n",
      "Iteration: 7720000\n",
      "Coef: [19.27333443 30.00108935]\n",
      "Loss: 0.06630340822982293\n",
      "Iteration: 7730000\n",
      "Coef: [19.27648196 30.00108944]\n",
      "Loss: 0.06573019050252882\n",
      "Iteration: 7740000\n",
      "Coef: [19.27961694 30.00108513]\n",
      "Loss: 0.06516195953075081\n",
      "Iteration: 7750000\n",
      "Coef: [19.28273703 30.00107527]\n",
      "Loss: 0.06459815383524649\n",
      "Iteration: 7760000\n",
      "Coef: [19.28584384 30.00107551]\n",
      "Loss: 0.06404145586660145\n",
      "Iteration: 7770000\n",
      "Coef: [19.28893695 30.00106617]\n",
      "Loss: 0.06348644422620439\n",
      "Iteration: 7780000\n",
      "Coef: [19.2920169  30.00106592]\n",
      "Loss: 0.06293770509036994\n",
      "Iteration: 7790000\n",
      "Coef: [19.29508458 30.00106177]\n",
      "Loss: 0.06239370156771969\n",
      "Iteration: 7800000\n",
      "Coef: [19.2981377  30.00105216]\n",
      "Loss: 0.061853921728756374\n",
      "Iteration: 7810000\n",
      "Coef: [19.30117782 30.00105252]\n",
      "Loss: 0.06132107469115852\n",
      "Iteration: 7820000\n",
      "Coef: [19.30420454 30.00104315]\n",
      "Loss: 0.06078956944944824\n",
      "Iteration: 7830000\n",
      "Coef: [19.30721838 30.00104324]\n",
      "Loss: 0.060264218371075824\n",
      "Iteration: 7840000\n",
      "Coef: [19.31022009 30.00103877]\n",
      "Loss: 0.05974293431824298\n",
      "Iteration: 7850000\n",
      "Coef: [19.31320766 30.00102963]\n",
      "Loss: 0.05922621490802013\n",
      "Iteration: 7860000\n",
      "Coef: [19.31618253 30.00102987]\n",
      "Loss: 0.058715916623023494\n",
      "Iteration: 7870000\n",
      "Coef: [19.31914428 30.00102073]\n",
      "Loss: 0.058207142379212505\n",
      "Iteration: 7880000\n",
      "Coef: [19.32209343 30.00102095]\n",
      "Loss: 0.05770420725759482\n",
      "Iteration: 7890000\n",
      "Coef: [19.32503071 30.00101661]\n",
      "Loss: 0.05720505876057486\n",
      "Iteration: 7900000\n",
      "Coef: [19.32795417 30.00100738]\n",
      "Loss: 0.056711621506766396\n",
      "Iteration: 7910000\n",
      "Coef: [19.33086516 30.00100809]\n",
      "Loss: 0.05622224796349913\n",
      "Iteration: 7920000\n",
      "Coef: [19.33376323 30.00099891]\n",
      "Loss: 0.0557342709117953\n",
      "Iteration: 7930000\n",
      "Coef: [19.33664905 30.00099906]\n",
      "Loss: 0.05525285671841749\n",
      "Iteration: 7940000\n",
      "Coef: [19.33952318 30.00099437]\n",
      "Loss: 0.054774571054010075\n",
      "Iteration: 7950000\n",
      "Coef: [19.34238398 30.00098558]\n",
      "Loss: 0.054302779069503045\n",
      "Iteration: 7960000\n",
      "Coef: [19.34523239 30.00098614]\n",
      "Loss: 0.05383319133584065\n",
      "Iteration: 7970000\n",
      "Coef: [19.34806834 30.00097717]\n",
      "Loss: 0.05336692834352921\n",
      "Iteration: 7980000\n",
      "Coef: [19.35089213 30.00097746]\n",
      "Loss: 0.05290544942475492\n",
      "Iteration: 7990000\n",
      "Coef: [19.35370456 30.00097297]\n",
      "Loss: 0.05244761186131851\n",
      "Iteration: 8000000\n",
      "Coef: [19.35650394 30.00096437]\n",
      "Loss: 0.051996010631641276\n",
      "Iteration: 8010000\n",
      "Coef: [19.35929121 30.00096511]\n",
      "Loss: 0.051546541562837084\n",
      "Iteration: 8020000\n",
      "Coef: [19.36206617 30.00095639]\n",
      "Loss: 0.051099563413440914\n",
      "Iteration: 8030000\n",
      "Coef: [19.36482944 30.00095684]\n",
      "Loss: 0.050658344695620985\n",
      "Iteration: 8040000\n",
      "Coef: [19.3675815  30.00095249]\n",
      "Loss: 0.05021983516006443\n",
      "Iteration: 8050000\n",
      "Coef: [19.37032071 30.00094374]\n",
      "Loss: 0.04978694720284713\n",
      "Iteration: 8060000\n",
      "Coef: [19.37304814 30.0009444 ]\n",
      "Loss: 0.04935677519086951\n",
      "Iteration: 8070000\n",
      "Coef: [19.37576354 30.00093583]\n",
      "Loss: 0.04892878280731717\n",
      "Iteration: 8080000\n",
      "Coef: [19.37846741 30.00093585]\n",
      "Loss: 0.04850579709193022\n",
      "Iteration: 8090000\n",
      "Coef: [19.38116039 30.0009317 ]\n",
      "Loss: 0.04808616706705499\n",
      "Iteration: 8100000\n",
      "Coef: [19.38384078 30.00092367]\n",
      "Loss: 0.047670465358993656\n",
      "Iteration: 8110000\n",
      "Coef: [19.38650968 30.00092392]\n",
      "Loss: 0.04725961145505991\n",
      "Iteration: 8120000\n",
      "Coef: [19.3891668  30.00091586]\n",
      "Loss: 0.04685006257563187\n",
      "Iteration: 8130000\n",
      "Coef: [19.39181272 30.0009162 ]\n",
      "Loss: 0.0464456367093557\n",
      "Iteration: 8140000\n",
      "Coef: [19.3944478 30.0009117]\n",
      "Loss: 0.04604337595989103\n",
      "Iteration: 8150000\n",
      "Coef: [19.39707065 30.00090374]\n",
      "Loss: 0.04564653392151857\n",
      "Iteration: 8160000\n",
      "Coef: [19.39968224 30.00090435]\n",
      "Loss: 0.04525243712317927\n",
      "Iteration: 8170000\n",
      "Coef: [19.40228233 30.00089595]\n",
      "Loss: 0.044860048013800995\n",
      "Iteration: 8180000\n",
      "Coef: [19.40487135 30.0008964 ]\n",
      "Loss: 0.0444723940451617\n",
      "Iteration: 8190000\n",
      "Coef: [19.40744987 30.00089206]\n",
      "Loss: 0.04408732655946666\n",
      "Iteration: 8200000\n",
      "Coef: [19.41001643 30.00088435]\n",
      "Loss: 0.04370733227651098\n",
      "Iteration: 8210000\n",
      "Coef: [19.41257186 30.00088452]\n",
      "Loss: 0.043329308542001274\n",
      "Iteration: 8220000\n",
      "Coef: [19.41511613 30.00087696]\n",
      "Loss: 0.042954046776876\n",
      "Iteration: 8230000\n",
      "Coef: [19.41764958 30.00087692]\n",
      "Loss: 0.0425828926058354\n",
      "Iteration: 8240000\n",
      "Coef: [19.42017274 30.00087279]\n",
      "Loss: 0.04221434778137414\n",
      "Iteration: 8250000\n",
      "Coef: [19.42268421 30.00086544]\n",
      "Loss: 0.04184951126542511\n",
      "Iteration: 8260000\n",
      "Coef: [19.42518488 30.00086595]\n",
      "Loss: 0.04148930530073958\n",
      "Iteration: 8270000\n",
      "Coef: [19.42767445 30.00085811]\n",
      "Loss: 0.041129294106209614\n",
      "Iteration: 8280000\n",
      "Coef: [19.4301535  30.00085823]\n",
      "Loss: 0.04077402321941574\n",
      "Iteration: 8290000\n",
      "Coef: [19.4326225  30.00085425]\n",
      "Loss: 0.04042111835231996\n",
      "Iteration: 8300000\n",
      "Coef: [19.43508005 30.00084656]\n",
      "Loss: 0.040073092076051385\n",
      "Iteration: 8310000\n",
      "Coef: [19.43752696 30.00084727]\n",
      "Loss: 0.03972661291649593\n",
      "Iteration: 8320000\n",
      "Coef: [19.43996308 30.00083968]\n",
      "Loss: 0.03938204679547832\n",
      "Iteration: 8330000\n",
      "Coef: [19.44238893 30.00083983]\n",
      "Loss: 0.0390418935890904\n",
      "Iteration: 8340000\n",
      "Coef: [19.44480493 30.00083596]\n",
      "Loss: 0.038703988681684974\n",
      "Iteration: 8350000\n",
      "Coef: [19.44720973 30.00082828]\n",
      "Loss: 0.03837093424543775\n",
      "Iteration: 8360000\n",
      "Coef: [19.44960401 30.0008289 ]\n",
      "Loss: 0.03803865681372036\n",
      "Iteration: 8370000\n",
      "Coef: [19.45198793 30.00082141]\n",
      "Loss: 0.037709268371038086\n",
      "Iteration: 8380000\n",
      "Coef: [19.45436161 30.00082175]\n",
      "Loss: 0.03738327500743713\n",
      "Iteration: 8390000\n",
      "Coef: [19.45672566 30.0008177 ]\n",
      "Loss: 0.03705960510221634\n",
      "Iteration: 8400000\n",
      "Coef: [19.45907883 30.00081078]\n",
      "Loss: 0.03674032258319105\n",
      "Iteration: 8410000\n",
      "Coef: [19.46142182 30.0008112 ]\n",
      "Loss: 0.03642285142640711\n",
      "Iteration: 8420000\n",
      "Coef: [19.46375447 30.00080395]\n",
      "Loss: 0.03610713644335477\n",
      "Iteration: 8430000\n",
      "Coef: [19.46607729 30.00080439]\n",
      "Loss: 0.035795443116998824\n",
      "Iteration: 8440000\n",
      "Coef: [19.4683906  30.00080037]\n",
      "Loss: 0.03548536409142105\n",
      "Iteration: 8450000\n",
      "Coef: [19.47069326 30.00079306]\n",
      "Loss: 0.03518009408035267\n",
      "Iteration: 8460000\n",
      "Coef: [19.47298587 30.00079378]\n",
      "Loss: 0.03487553916158958\n",
      "Iteration: 8470000\n",
      "Coef: [19.47526845 30.00078664]\n",
      "Loss: 0.03457327656556826\n",
      "Iteration: 8480000\n",
      "Coef: [19.47754142 30.00078719]\n",
      "Loss: 0.03427484467818523\n",
      "Iteration: 8490000\n",
      "Coef: [19.47980497 30.00078298]\n",
      "Loss: 0.033977774387161125\n",
      "Iteration: 8500000\n",
      "Coef: [19.48205821 30.00077623]\n",
      "Loss: 0.03368521157591487\n",
      "Iteration: 8510000\n",
      "Coef: [19.4843016 30.0007766]\n",
      "Loss: 0.033393759474261306\n",
      "Iteration: 8520000\n",
      "Coef: [19.48653519 30.00076981]\n",
      "Loss: 0.03310448029718325\n",
      "Iteration: 8530000\n",
      "Coef: [19.48875927 30.00076989]\n",
      "Loss: 0.03281841865436921\n",
      "Iteration: 8540000\n",
      "Coef: [19.49097434 30.00076618]\n",
      "Loss: 0.032534337053396534\n",
      "Iteration: 8550000\n",
      "Coef: [19.49317921 30.0007595 ]\n",
      "Loss: 0.032254308096105896\n",
      "Iteration: 8560000\n",
      "Coef: [19.49537445 30.00076006]\n",
      "Loss: 0.03197531350766061\n",
      "Iteration: 8570000\n",
      "Coef: [19.49756009 30.00075317]\n",
      "Loss: 0.031698239304725664\n",
      "Iteration: 8580000\n",
      "Coef: [19.49973643 30.00075358]\n",
      "Loss: 0.03142441332809889\n",
      "Iteration: 8590000\n",
      "Coef: [19.50190386 30.00074968]\n",
      "Loss: 0.031152192927531006\n",
      "Iteration: 8600000\n",
      "Coef: [19.50406139 30.00074317]\n",
      "Loss: 0.03088411351380638\n",
      "Iteration: 8610000\n",
      "Coef: [19.50620942 30.00074346]\n",
      "Loss: 0.030616559968780183\n",
      "Iteration: 8620000\n",
      "Coef: [19.50834823 30.00073685]\n",
      "Loss: 0.030351778668658447\n",
      "Iteration: 8630000\n",
      "Coef: [19.51047777 30.00073722]\n",
      "Loss: 0.030089300534732688\n",
      "Iteration: 8640000\n",
      "Coef: [19.51259875 30.00073379]\n",
      "Loss: 0.029828886228514415\n",
      "Iteration: 8650000\n",
      "Coef: [19.5147099  30.00072727]\n",
      "Loss: 0.02957200080872987\n",
      "Iteration: 8660000\n",
      "Coef: [19.51681182 30.00072748]\n",
      "Loss: 0.02931588649979884\n",
      "Iteration: 8670000\n",
      "Coef: [19.51890471 30.00072098]\n",
      "Loss: 0.029062420726947997\n",
      "Iteration: 8680000\n",
      "Coef: [19.52098854 30.00072154]\n",
      "Loss: 0.028811165579505648\n",
      "Iteration: 8690000\n",
      "Coef: [19.52306392 30.00071787]\n",
      "Loss: 0.028561623982758508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8700000\n",
      "Coef: [19.52512974 30.00071178]\n",
      "Loss: 0.028314840967803123\n",
      "Iteration: 8710000\n",
      "Coef: [19.52718663 30.00071212]\n",
      "Loss: 0.028070817158993844\n",
      "Iteration: 8720000\n",
      "Coef: [19.52923451 30.00070553]\n",
      "Loss: 0.02782776796274784\n",
      "Iteration: 8730000\n",
      "Coef: [19.53127362 30.000706  ]\n",
      "Loss: 0.027587172962010745\n",
      "Iteration: 8740000\n",
      "Coef: [19.53330444 30.00070248]\n",
      "Loss: 0.027348282858139013\n",
      "Iteration: 8750000\n",
      "Coef: [19.53532593 30.00069643]\n",
      "Loss: 0.027112727105924207\n",
      "Iteration: 8760000\n",
      "Coef: [19.53733857 30.00069665]\n",
      "Loss: 0.026878095394471363\n",
      "Iteration: 8770000\n",
      "Coef: [19.5393425  30.00069049]\n",
      "Loss: 0.026645488319232618\n",
      "Iteration: 8780000\n",
      "Coef: [19.54133783 30.00069081]\n",
      "Loss: 0.02641519863537807\n",
      "Iteration: 8790000\n",
      "Coef: [19.54332507 30.00068739]\n",
      "Loss: 0.02618647484004495\n",
      "Iteration: 8800000\n",
      "Coef: [19.54530315 30.00068142]\n",
      "Loss: 0.025961014568726747\n",
      "Iteration: 8810000\n",
      "Coef: [19.54727261 30.00068174]\n",
      "Loss: 0.025736312626232678\n",
      "Iteration: 8820000\n",
      "Coef: [19.54923352 30.00067557]\n",
      "Loss: 0.025513622441923213\n",
      "Iteration: 8830000\n",
      "Coef: [19.55118601 30.00067619]\n",
      "Loss: 0.025293199466261344\n",
      "Iteration: 8840000\n",
      "Coef: [19.55313058 30.00067287]\n",
      "Loss: 0.025074131037880844\n",
      "Iteration: 8850000\n",
      "Coef: [19.55506614 30.00066685]\n",
      "Loss: 0.02485804339022676\n",
      "Iteration: 8860000\n",
      "Coef: [19.55699332 30.00066709]\n",
      "Loss: 0.024642971083118984\n",
      "Iteration: 8870000\n",
      "Coef: [19.55891214 30.00066104]\n",
      "Loss: 0.0244297704825543\n",
      "Iteration: 8880000\n",
      "Coef: [19.56082273 30.00066175]\n",
      "Loss: 0.024218757487672216\n",
      "Iteration: 8890000\n",
      "Coef: [19.56272548 30.00065824]\n",
      "Loss: 0.024008854778239754\n",
      "Iteration: 8900000\n",
      "Coef: [19.56461955 30.00065227]\n",
      "Loss: 0.02380243579812732\n",
      "Iteration: 8910000\n",
      "Coef: [19.56650529 30.00065272]\n",
      "Loss: 0.02359603901925039\n",
      "Iteration: 8920000\n",
      "Coef: [19.56838293 30.00064686]\n",
      "Loss: 0.023391937294790503\n",
      "Iteration: 8930000\n",
      "Coef: [19.57025243 30.00064719]\n",
      "Loss: 0.02318962554615358\n",
      "Iteration: 8940000\n",
      "Coef: [19.57211442 30.00064412]\n",
      "Loss: 0.02298891739387278\n",
      "Iteration: 8950000\n",
      "Coef: [19.57396783 30.00063822]\n",
      "Loss: 0.022791334533468367\n",
      "Iteration: 8960000\n",
      "Coef: [19.57581302 30.00063852]\n",
      "Loss: 0.02259344927756833\n",
      "Iteration: 8970000\n",
      "Coef: [19.57765035 30.00063309]\n",
      "Loss: 0.02239811125361464\n",
      "Iteration: 8980000\n",
      "Coef: [19.57947979 30.00063359]\n",
      "Loss: 0.022204713567980584\n",
      "Iteration: 8990000\n",
      "Coef: [19.58130173 30.00063032]\n",
      "Loss: 0.02201231778937141\n",
      "Iteration: 9000000\n",
      "Coef: [19.58311529 30.00062479]\n",
      "Loss: 0.021822706982766883\n",
      "Iteration: 9010000\n",
      "Coef: [19.58492095 30.0006249 ]\n",
      "Loss: 0.021633719530535802\n",
      "Iteration: 9020000\n",
      "Coef: [19.58671883 30.00061937]\n",
      "Loss: 0.021446699172910602\n",
      "Iteration: 9030000\n",
      "Coef: [19.58850894 30.00061982]\n",
      "Loss: 0.02126128195853061\n",
      "Iteration: 9040000\n",
      "Coef: [19.59029176 30.00061673]\n",
      "Loss: 0.021077170923274054\n",
      "Iteration: 9050000\n",
      "Coef: [19.59206639 30.00061138]\n",
      "Loss: 0.020895631888215617\n",
      "Iteration: 9060000\n",
      "Coef: [19.59383328 30.00061153]\n",
      "Loss: 0.020714729558481228\n",
      "Iteration: 9070000\n",
      "Coef: [19.59559251 30.00060626]\n",
      "Loss: 0.02053545434170577\n",
      "Iteration: 9080000\n",
      "Coef: [19.59734425 30.00060669]\n",
      "Loss: 0.02035820241443286\n",
      "Iteration: 9090000\n",
      "Coef: [19.59908882 30.00060361]\n",
      "Loss: 0.020181824171964503\n",
      "Iteration: 9100000\n",
      "Coef: [19.60082535 30.00059802]\n",
      "Loss: 0.020008272191377102\n",
      "Iteration: 9110000\n",
      "Coef: [19.60255425 30.00059837]\n",
      "Loss: 0.01983470111264023\n",
      "Iteration: 9120000\n",
      "Coef: [19.60427571 30.00059323]\n",
      "Loss: 0.019663083084872694\n",
      "Iteration: 9130000\n",
      "Coef: [19.60598979 30.0005934 ]\n",
      "Loss: 0.019493157430048886\n",
      "Iteration: 9140000\n",
      "Coef: [19.6076969  30.00059048]\n",
      "Loss: 0.019324399810697734\n",
      "Iteration: 9150000\n",
      "Coef: [19.60939617 30.00058539]\n",
      "Loss: 0.019157981479633414\n",
      "Iteration: 9160000\n",
      "Coef: [19.61108796 30.00058535]\n",
      "Loss: 0.018991932703842817\n",
      "Iteration: 9170000\n",
      "Coef: [19.61277253 30.00058035]\n",
      "Loss: 0.01882786024312818\n",
      "Iteration: 9180000\n",
      "Coef: [19.61444982 30.00058087]\n",
      "Loss: 0.018665191601320213\n",
      "Iteration: 9190000\n",
      "Coef: [19.61612029 30.00057799]\n",
      "Loss: 0.018503530292158607\n",
      "Iteration: 9200000\n",
      "Coef: [19.61778308 30.00057253]\n",
      "Loss: 0.018344532229788907\n",
      "Iteration: 9210000\n",
      "Coef: [19.61943849 30.00057282]\n",
      "Loss: 0.018185145858401853\n",
      "Iteration: 9220000\n",
      "Coef: [19.62108691 30.00056784]\n",
      "Loss: 0.018028046350371918\n",
      "Iteration: 9230000\n",
      "Coef: [19.62272813 30.00056816]\n",
      "Loss: 0.017872099779898617\n",
      "Iteration: 9240000\n",
      "Coef: [19.62436274 30.00056546]\n",
      "Loss: 0.017717417565754453\n",
      "Iteration: 9250000\n",
      "Coef: [19.62598983 30.00056034]\n",
      "Loss: 0.017565058666794725\n",
      "Iteration: 9260000\n",
      "Coef: [19.6276097  30.00056051]\n",
      "Loss: 0.017412597328304774\n",
      "Iteration: 9270000\n",
      "Coef: [19.62922273 30.00055561]\n",
      "Loss: 0.01726221316377129\n",
      "Iteration: 9280000\n",
      "Coef: [19.63082872 30.00055608]\n",
      "Loss: 0.017112935500830758\n",
      "Iteration: 9290000\n",
      "Coef: [19.63242823 30.00055348]\n",
      "Loss: 0.016964813036382625\n",
      "Iteration: 9300000\n",
      "Coef: [19.63402034 30.00054837]\n",
      "Loss: 0.016818774329725065\n",
      "Iteration: 9310000\n",
      "Coef: [19.63560544 30.00054845]\n",
      "Loss: 0.016672856633921415\n",
      "Iteration: 9320000\n",
      "Coef: [19.63718378 30.0005439 ]\n",
      "Loss: 0.016528725376787637\n",
      "Iteration: 9330000\n",
      "Coef: [19.63875535 30.00054424]\n",
      "Loss: 0.01638601316808136\n",
      "Iteration: 9340000\n",
      "Coef: [19.64032048 30.00054141]\n",
      "Loss: 0.0162440481669638\n",
      "Iteration: 9350000\n",
      "Coef: [19.64187848 30.00053651]\n",
      "Loss: 0.01610440474305915\n",
      "Iteration: 9360000\n",
      "Coef: [19.64342955 30.00053678]\n",
      "Loss: 0.015964648641145253\n",
      "Iteration: 9370000\n",
      "Coef: [19.64497402 30.00053207]\n",
      "Loss: 0.015826652795521545\n",
      "Iteration: 9380000\n",
      "Coef: [19.6465118  30.00053245]\n",
      "Loss: 0.01568983263705508\n",
      "Iteration: 9390000\n",
      "Coef: [19.64804339 30.00052999]\n",
      "Loss: 0.015554044276200375\n",
      "Iteration: 9400000\n",
      "Coef: [19.64956788 30.00052495]\n",
      "Loss: 0.015420305765976881\n",
      "Iteration: 9410000\n",
      "Coef: [19.65108566 30.00052528]\n",
      "Loss: 0.015286457048492585\n",
      "Iteration: 9420000\n",
      "Coef: [19.65259697 30.00052059]\n",
      "Loss: 0.015154341921373538\n",
      "Iteration: 9430000\n",
      "Coef: [19.65410168 30.00052087]\n",
      "Loss: 0.015023214801612405\n",
      "Iteration: 9440000\n",
      "Coef: [19.6556004  30.00051849]\n",
      "Loss: 0.014893232727848354\n",
      "Iteration: 9450000\n",
      "Coef: [19.65709216 30.00051377]\n",
      "Loss: 0.014765102593235277\n",
      "Iteration: 9460000\n",
      "Coef: [19.65857737 30.00051398]\n",
      "Loss: 0.014637041717326986\n",
      "Iteration: 9470000\n",
      "Coef: [19.66005624 30.00050941]\n",
      "Loss: 0.01451056089873173\n",
      "Iteration: 9480000\n",
      "Coef: [19.66152865 30.00050973]\n",
      "Loss: 0.014385021380055835\n",
      "Iteration: 9490000\n",
      "Coef: [19.66299519 30.00050748]\n",
      "Loss: 0.014260583858755994\n",
      "Iteration: 9500000\n",
      "Coef: [19.66445493 30.00050259]\n",
      "Loss: 0.01413804785078804\n",
      "Iteration: 9510000\n",
      "Coef: [19.66590819 30.0005029 ]\n",
      "Loss: 0.014015197570201848\n",
      "Iteration: 9520000\n",
      "Coef: [19.66735532 30.00049848]\n",
      "Loss: 0.013894118114250452\n",
      "Iteration: 9530000\n",
      "Coef: [19.66879613 30.00049879]\n",
      "Loss: 0.013773919772388678\n",
      "Iteration: 9540000\n",
      "Coef: [19.67023113 30.00049639]\n",
      "Loss: 0.013654699073858644\n",
      "Iteration: 9550000\n",
      "Coef: [19.67165954 30.00049198]\n",
      "Loss: 0.013537207883198399\n",
      "Iteration: 9560000\n",
      "Coef: [19.67308166 30.00049221]\n",
      "Loss: 0.013419886514320736\n",
      "Iteration: 9570000\n",
      "Coef: [19.67449767 30.00048786]\n",
      "Loss: 0.013303816977778916\n",
      "Iteration: 9580000\n",
      "Coef: [19.67590754 30.00048806]\n",
      "Loss: 0.01318877020396058\n",
      "Iteration: 9590000\n",
      "Coef: [19.67731175 30.00048572]\n",
      "Loss: 0.01307462009518575\n",
      "Iteration: 9600000\n",
      "Coef: [19.6787095  30.00048139]\n",
      "Loss: 0.01296214719932467\n",
      "Iteration: 9610000\n",
      "Coef: [19.68010104 30.00048148]\n",
      "Loss: 0.0128496649588662\n",
      "Iteration: 9620000\n",
      "Coef: [19.6814867  30.00047728]\n",
      "Loss: 0.012738707981420405\n",
      "Iteration: 9630000\n",
      "Coef: [19.68286625 30.00047749]\n",
      "Loss: 0.012628441431139012\n",
      "Iteration: 9640000\n",
      "Coef: [19.68424036 30.00047549]\n",
      "Loss: 0.012519251284182228\n",
      "Iteration: 9650000\n",
      "Coef: [19.68560806 30.00047104]\n",
      "Loss: 0.012411499695774972\n",
      "Iteration: 9660000\n",
      "Coef: [19.68696973 30.00047116]\n",
      "Loss: 0.012303802643935668\n",
      "Iteration: 9670000\n",
      "Coef: [19.6883256  30.00046721]\n",
      "Loss: 0.012197439692014372\n",
      "Iteration: 9680000\n",
      "Coef: [19.6896756 30.0004673]\n",
      "Loss: 0.01209198735736813\n",
      "Iteration: 9690000\n",
      "Coef: [19.69102016 30.00046513]\n",
      "Loss: 0.011987360746315137\n",
      "Iteration: 9700000\n",
      "Coef: [19.69235854 30.00046076]\n",
      "Loss: 0.011884436136128981\n",
      "Iteration: 9710000\n",
      "Coef: [19.69369098 30.00046121]\n",
      "Loss: 0.011781227380629995\n",
      "Iteration: 9720000\n",
      "Coef: [19.69501775 30.00045695]\n",
      "Loss: 0.011679402678484899\n",
      "Iteration: 9730000\n",
      "Coef: [19.69633871 30.00045731]\n",
      "Loss: 0.011578317396954077\n",
      "Iteration: 9740000\n",
      "Coef: [19.69765441 30.00045523]\n",
      "Loss: 0.011478140121349295\n",
      "Iteration: 9750000\n",
      "Coef: [19.69896402 30.00045101]\n",
      "Loss: 0.011379389971183906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9760000\n",
      "Coef: [19.70026786 30.00045123]\n",
      "Loss: 0.011280681293946786\n",
      "Iteration: 9770000\n",
      "Coef: [19.70156614 30.00044721]\n",
      "Loss: 0.011183194864081217\n",
      "Iteration: 9780000\n",
      "Coef: [19.70285875 30.00044748]\n",
      "Loss: 0.011086443396906629\n",
      "Iteration: 9790000\n",
      "Coef: [19.70414621 30.00044547]\n",
      "Loss: 0.01099053259478486\n",
      "Iteration: 9800000\n",
      "Coef: [19.7054277  30.00044126]\n",
      "Loss: 0.010896054561845822\n",
      "Iteration: 9810000\n",
      "Coef: [19.7067035  30.00044145]\n",
      "Loss: 0.010801402527678148\n",
      "Iteration: 9820000\n",
      "Coef: [19.70797391 30.00043767]\n",
      "Loss: 0.010708080327339213\n",
      "Iteration: 9830000\n",
      "Coef: [19.70923878 30.00043781]\n",
      "Loss: 0.010615446365376029\n",
      "Iteration: 9840000\n",
      "Coef: [19.71049859 30.0004359 ]\n",
      "Loss: 0.010523636494929411\n",
      "Iteration: 9850000\n",
      "Coef: [19.71175258 30.00043174]\n",
      "Loss: 0.010433219907372816\n",
      "Iteration: 9860000\n",
      "Coef: [19.713001   30.00043201]\n",
      "Loss: 0.010342562443904548\n",
      "Iteration: 9870000\n",
      "Coef: [19.71424414 30.00042821]\n",
      "Loss: 0.010253212090917134\n",
      "Iteration: 9880000\n",
      "Coef: [19.71548186 30.00042852]\n",
      "Loss: 0.010164528973239299\n",
      "Iteration: 9890000\n",
      "Coef: [19.71671459 30.00042645]\n",
      "Loss: 0.01007654422349191\n",
      "Iteration: 9900000\n",
      "Coef: [19.71794166 30.0004226 ]\n",
      "Loss: 0.009989851289161935\n",
      "Iteration: 9910000\n",
      "Coef: [19.71916332 30.00042286]\n",
      "Loss: 0.009903268704206913\n",
      "Iteration: 9920000\n",
      "Coef: [19.72037974 30.00041906]\n",
      "Loss: 0.009817612285132938\n",
      "Iteration: 9930000\n",
      "Coef: [19.72159089 30.0004193 ]\n",
      "Loss: 0.009732712217092298\n",
      "Iteration: 9940000\n",
      "Coef: [19.72279715 30.00041731]\n",
      "Loss: 0.009648479029116343\n",
      "Iteration: 9950000\n",
      "Coef: [19.72399788 30.00041343]\n",
      "Loss: 0.009565569649358292\n",
      "Iteration: 9960000\n",
      "Coef: [19.72519328 30.00041367]\n",
      "Loss: 0.009482491062049014\n",
      "Iteration: 9970000\n",
      "Coef: [19.72638363 30.00040992]\n",
      "Loss: 0.00940062023903166\n",
      "Iteration: 9980000\n",
      "Coef: [19.72756873 30.00041026]\n",
      "Loss: 0.009319231639820432\n",
      "Iteration: 9990000\n",
      "Coef: [19.72874911 30.00040833]\n",
      "Loss: 0.009238586712403357\n"
     ]
    }
   ],
   "source": [
    "clf = Linear_Regression(alpha = 1, num_iter = 10000000, init_weight= np.mat([15,25]).T)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normaliz(lst):\n",
    "    \"\"\"\n",
    "    Helper function for normalize for faster training.\n",
    "    \"\"\"\n",
    "    maximum = np.max(lst)\n",
    "    minimum = np.min(lst)\n",
    "\n",
    "    return (lst - minimum) / (maximum - minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We generate some easy data for testing. We should fit a line with, $Y = 30 * X + 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(np.mat(np.arange(1, 1000, 5)).T)\n",
    "y = np.array((30 * X)).flatten() +  20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do NOT modify the following line, just run it when you are done.  You can also try different initialization, you will notice different coef at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Coef: [ 0.42098047 -0.74923399]\n",
      "Loss: 6.922957560642464e+23\n",
      "Iteration: 10000\n",
      "Coef: [ 0.5502826  30.02928257]\n",
      "Loss: 47.4996584138212\n",
      "Iteration: 20000\n",
      "Coef: [ 0.63452696 30.0290271 ]\n",
      "Loss: 47.089956401100125\n",
      "Iteration: 30000\n",
      "Coef: [ 0.71840969 30.02904733]\n",
      "Loss: 46.68332213380334\n",
      "Iteration: 40000\n",
      "Coef: [ 0.80191907 30.02878545]\n",
      "Loss: 46.278465676570356\n",
      "Iteration: 50000\n",
      "Coef: [ 0.88510615 30.02864223]\n",
      "Loss: 45.87857211055696\n",
      "Iteration: 60000\n",
      "Coef: [ 0.96789761 30.02865621]\n",
      "Loss: 45.481827704173845\n",
      "Iteration: 70000\n",
      "Coef: [ 1.05033338 30.02839836]\n",
      "Loss: 45.08977629266094\n",
      "Iteration: 80000\n",
      "Coef: [ 1.1324124  30.02841669]\n",
      "Loss: 44.69978528920356\n",
      "Iteration: 90000\n",
      "Coef: [ 1.21413249 30.02816001]\n",
      "Loss: 44.31266652231411\n",
      "Iteration: 100000\n",
      "Coef: [ 1.29553081 30.02803047]\n",
      "Loss: 43.929488315075616\n",
      "Iteration: 110000\n",
      "Coef: [ 1.37654505 30.02804007]\n",
      "Loss: 43.549653580926204\n",
      "Iteration: 120000\n",
      "Coef: [ 1.45721145 30.02778834]\n",
      "Loss: 43.17428376974248\n",
      "Iteration: 130000\n",
      "Coef: [ 1.53752833 30.02781042]\n",
      "Loss: 42.8010273422935\n",
      "Iteration: 140000\n",
      "Coef: [ 1.61749115 30.02756195]\n",
      "Loss: 42.429999649396066\n",
      "Iteration: 150000\n",
      "Coef: [ 1.69714523 30.02742061]\n",
      "Loss: 42.06345908152177\n",
      "Iteration: 160000\n",
      "Coef: [ 1.77641747 30.02743428]\n",
      "Loss: 41.699509694504414\n",
      "Iteration: 170000\n",
      "Coef: [ 1.8553521  30.02719279]\n",
      "Loss: 41.34009540525833\n",
      "Iteration: 180000\n",
      "Coef: [ 1.93394494 30.02721423]\n",
      "Loss: 40.982798333326166\n",
      "Iteration: 190000\n",
      "Coef: [ 2.01219134 30.02696807]\n",
      "Loss: 40.627542591543005\n",
      "Iteration: 200000\n",
      "Coef: [ 2.09013248 30.02684039]\n",
      "Loss: 40.2763354432118\n",
      "Iteration: 210000\n",
      "Coef: [ 2.16770314 30.0268399 ]\n",
      "Loss: 39.92794579819486\n",
      "Iteration: 220000\n",
      "Coef: [ 2.24494336 30.02661294]\n",
      "Loss: 39.583686023080766\n",
      "Iteration: 230000\n",
      "Coef: [ 2.32184919 30.02662709]\n",
      "Loss: 39.24164058550145\n",
      "Iteration: 240000\n",
      "Coef: [ 2.39841587 30.02638903]\n",
      "Loss: 38.901605760806454\n",
      "Iteration: 250000\n",
      "Coef: [ 2.47468401 30.02626265]\n",
      "Loss: 38.56534859592128\n",
      "Iteration: 260000\n",
      "Coef: [ 2.55058983 30.02626526]\n",
      "Loss: 38.23175349203947\n",
      "Iteration: 270000\n",
      "Coef: [ 2.62617223 30.02603875]\n",
      "Loss: 37.902221170962434\n",
      "Iteration: 280000\n",
      "Coef: [ 2.70142734 30.02606018]\n",
      "Loss: 37.57478673513647\n",
      "Iteration: 290000\n",
      "Coef: [ 2.7763504  30.02581689]\n",
      "Loss: 37.24912780744192\n",
      "Iteration: 300000\n",
      "Coef: [ 2.85098122 30.02568912]\n",
      "Loss: 36.92722463880144\n",
      "Iteration: 310000\n",
      "Coef: [ 2.92525472 30.02570018]\n",
      "Loss: 36.60757496756708\n",
      "Iteration: 320000\n",
      "Coef: [ 2.99921414 30.02547655]\n",
      "Loss: 36.2922149263156\n",
      "Iteration: 330000\n",
      "Coef: [ 3.0728512  30.02549153]\n",
      "Loss: 35.978151638695074\n",
      "Iteration: 340000\n",
      "Coef: [ 3.14616613 30.02526866]\n",
      "Loss: 35.66655755518311\n",
      "Iteration: 350000\n",
      "Coef: [ 3.21919492 30.02514334]\n",
      "Loss: 35.35835716753276\n",
      "Iteration: 360000\n",
      "Coef: [ 3.291874  30.0251461]\n",
      "Loss: 35.0523820301443\n",
      "Iteration: 370000\n",
      "Coef: [ 3.36424561 30.0249295 ]\n",
      "Loss: 34.75045268904831\n",
      "Iteration: 380000\n",
      "Coef: [ 3.43630178 30.02494731]\n",
      "Loss: 34.44985421379695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a9b1225b6465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear_Regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_weight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d9ef8e9a2423>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(self.X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m#self.coef = self.init_weight #### Please change this after you get the example right.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d9ef8e9a2423>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mpre_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprevious_y_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mcurrent_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m### This is the early stop, don't modify fllowing three lines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = Linear_Regression(alpha = 1, num_iter = 10000000, init_weight= np.mat([15,25]).T)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  As the number of iteration increase, you should notice the coeficient converges to [20, 30]. \n",
    "#### It maybe very slow update. Feel free to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.46593641, 30.02489476])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   33.49083117,   183.61530499,   333.73977881,   483.86425263,\n",
       "         633.98872645,   784.11320027,   934.23767409,  1084.36214791,\n",
       "        1234.48662173,  1384.61109555,  1534.73556936,  1684.86004318,\n",
       "        1834.984517  ,  1985.10899082,  2135.23346464,  2285.35793846,\n",
       "        2435.48241228,  2585.6068861 ,  2735.73135992,  2885.85583374,\n",
       "        3035.98030756,  3186.10478137,  3336.22925519,  3486.35372901,\n",
       "        3636.47820283,  3786.60267665,  3936.72715047,  4086.85162429,\n",
       "        4236.97609811,  4387.10057193,  4537.22504575,  4687.34951957,\n",
       "        4837.47399338,  4987.5984672 ,  5137.72294102,  5287.84741484,\n",
       "        5437.97188866,  5588.09636248,  5738.2208363 ,  5888.34531012,\n",
       "        6038.46978394,  6188.59425776,  6338.71873158,  6488.84320539,\n",
       "        6638.96767921,  6789.09215303,  6939.21662685,  7089.34110067,\n",
       "        7239.46557449,  7389.59004831,  7539.71452213,  7689.83899595,\n",
       "        7839.96346977,  7990.08794359,  8140.2124174 ,  8290.33689122,\n",
       "        8440.46136504,  8590.58583886,  8740.71031268,  8890.8347865 ,\n",
       "        9040.95926032,  9191.08373414,  9341.20820796,  9491.33268178,\n",
       "        9641.4571556 ,  9791.58162941,  9941.70610323, 10091.83057705,\n",
       "       10241.95505087, 10392.07952469, 10542.20399851, 10692.32847233,\n",
       "       10842.45294615, 10992.57741997, 11142.70189379, 11292.82636761,\n",
       "       11442.95084142, 11593.07531524, 11743.19978906, 11893.32426288,\n",
       "       12043.4487367 , 12193.57321052, 12343.69768434, 12493.82215816,\n",
       "       12643.94663198, 12794.0711058 , 12944.19557962, 13094.32005343,\n",
       "       13244.44452725, 13394.56900107, 13544.69347489, 13694.81794871,\n",
       "       13844.94242253, 13995.06689635, 14145.19137017, 14295.31584399,\n",
       "       14445.44031781, 14595.56479163, 14745.68926544, 14895.81373926,\n",
       "       15045.93821308, 15196.0626869 , 15346.18716072, 15496.31163454,\n",
       "       15646.43610836, 15796.56058218, 15946.685056  , 16096.80952982,\n",
       "       16246.93400364, 16397.05847745, 16547.18295127, 16697.30742509,\n",
       "       16847.43189891, 16997.55637273, 17147.68084655, 17297.80532037,\n",
       "       17447.92979419, 17598.05426801, 17748.17874183, 17898.30321565,\n",
       "       18048.42768946, 18198.55216328, 18348.6766371 , 18498.80111092,\n",
       "       18648.92558474, 18799.05005856, 18949.17453238, 19099.2990062 ,\n",
       "       19249.42348002, 19399.54795384, 19549.67242765, 19699.79690147,\n",
       "       19849.92137529, 20000.04584911, 20150.17032293, 20300.29479675,\n",
       "       20450.41927057, 20600.54374439, 20750.66821821, 20900.79269203,\n",
       "       21050.91716585, 21201.04163966, 21351.16611348, 21501.2905873 ,\n",
       "       21651.41506112, 21801.53953494, 21951.66400876, 22101.78848258,\n",
       "       22251.9129564 , 22402.03743022, 22552.16190404, 22702.28637786,\n",
       "       22852.41085167, 23002.53532549, 23152.65979931, 23302.78427313,\n",
       "       23452.90874695, 23603.03322077, 23753.15769459, 23903.28216841,\n",
       "       24053.40664223, 24203.53111605, 24353.65558987, 24503.78006368,\n",
       "       24653.9045375 , 24804.02901132, 24954.15348514, 25104.27795896,\n",
       "       25254.40243278, 25404.5269066 , 25554.65138042, 25704.77585424,\n",
       "       25854.90032806, 26005.02480188, 26155.14927569, 26305.27374951,\n",
       "       26455.39822333, 26605.52269715, 26755.64717097, 26905.77164479,\n",
       "       27055.89611861, 27206.02059243, 27356.14506625, 27506.26954007,\n",
       "       27656.39401389, 27806.5184877 , 27956.64296152, 28106.76743534,\n",
       "       28256.89190916, 28407.01638298, 28557.1408568 , 28707.26533062,\n",
       "       28857.38980444, 29007.51427826, 29157.63875208, 29307.7632259 ,\n",
       "       29457.88769971, 29608.01217353, 29758.13664735, 29908.26112117])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please try to normalize the X and fit again with normalized X. You should find something interesting. Also think about what you should do for predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can also try this with the wine dataset we use in HW1. Try fit this function to that dataset with same features. If you look closely to the updates of coefficients. What do you find? This could be mentioned in your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import urllib\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url_Wine = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "wine = urllib.request.urlopen(url_Wine)\n",
    "wine = pd.read_csv(wine, delimiter=';')\n",
    "X = wine[['density','alcohol']]\n",
    "y = wine.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.667698877433"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "## Squared Error with sklearn.\n",
    "sum((lr.predict(X) - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will notice different coefficients, but the loss is very close to each other like 805. In your report, briefly discuss this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Coef: [ 0.28648257  0.29078582 -0.73242488]\n",
      "Loss: 2593711756702.465\n",
      "Iteration: 10000\n",
      "Coef: [0.74186652 0.75252285 0.39747606]\n",
      "Loss: 0.25266317955751927\n",
      "Iteration: 20000\n",
      "Coef: [0.86238171 0.87845194 0.3737943 ]\n",
      "Loss: 0.2519973588859396\n",
      "Iteration: 30000\n",
      "Coef: [0.9031094  0.92409811 0.36569768]\n",
      "Loss: 0.2519161201603733\n",
      "Iteration: 40000\n",
      "Coef: [0.91585542 0.94158892 0.36279308]\n",
      "Loss: 0.2519059710624162\n",
      "Iteration: 50000\n",
      "Coef: [0.91880748 0.94922594 0.36179877]\n",
      "Loss: 0.25190453565964555\n",
      "Iteration: 60000\n",
      "Coef: [0.91832607 0.95340697 0.36145585]\n",
      "Loss: 0.251904176444995\n",
      "Iteration: 70000\n",
      "Coef: [0.91664141 0.95637696 0.3613293 ]\n",
      "Loss: 0.2519039467244294\n",
      "Iteration: 80000\n",
      "Coef: [0.91453661 0.95892422 0.3612932 ]\n",
      "Loss: 0.2519037338428599\n",
      "Iteration: 90000\n",
      "Coef: [0.91228342 0.96132186 0.36127434]\n",
      "Loss: 0.2519035229335041\n",
      "Iteration: 100000\n",
      "Coef: [0.9099787  0.96366862 0.36127191]\n",
      "Loss: 0.25190331187009035\n",
      "Iteration: 110000\n",
      "Coef: [0.90765706 0.96599679 0.36127715]\n",
      "Loss: 0.2519031020685916\n",
      "Iteration: 120000\n",
      "Coef: [0.90532849 0.9683173  0.36127366]\n",
      "Loss: 0.25190289092777995\n",
      "Iteration: 130000\n",
      "Coef: [0.90299861 0.9706365  0.36128031]\n",
      "Loss: 0.2519026804791853\n",
      "Iteration: 140000\n",
      "Coef: [0.90066711 0.97295375 0.36127646]\n",
      "Loss: 0.2519024700656128\n",
      "Iteration: 150000\n",
      "Coef: [0.89833547 0.97527184 0.36127923]\n",
      "Loss: 0.25190225918001125\n",
      "Iteration: 160000\n",
      "Coef: [0.89600496 0.97758951 0.36128683]\n",
      "Loss: 0.25190204980801184\n",
      "Iteration: 170000\n",
      "Coef: [0.89367371 0.97990576 0.3612833 ]\n",
      "Loss: 0.25190183868101584\n",
      "Iteration: 180000\n",
      "Coef: [0.89134353 0.98222292 0.36129042]\n",
      "Loss: 0.25190162813786304\n",
      "Iteration: 190000\n",
      "Coef: [0.8890124  0.984539   0.36128682]\n",
      "Loss: 0.25190141787257186\n",
      "Iteration: 200000\n",
      "Coef: [0.8866814  0.98685613 0.36128946]\n",
      "Loss: 0.25190120719664216\n",
      "Iteration: 210000\n",
      "Coef: [0.88435167 0.98917299 0.36129741]\n",
      "Loss: 0.2519009982068288\n",
      "Iteration: 220000\n",
      "Coef: [0.88202126 0.99148835 0.36129385]\n",
      "Loss: 0.2519007868236246\n",
      "Iteration: 230000\n",
      "Coef: [0.87969177 0.99380484 0.36130105]\n",
      "Loss: 0.2519005767185202\n",
      "Iteration: 240000\n",
      "Coef: [0.87736151 0.99612003 0.36129731]\n",
      "Loss: 0.2519003663677849\n",
      "Iteration: 250000\n",
      "Coef: [0.87503127 0.99843638 0.3612999 ]\n",
      "Loss: 0.251900155875068\n",
      "Iteration: 260000\n",
      "Coef: [0.8727023  1.00075245 0.36130761]\n",
      "Loss: 0.25189994693770734\n",
      "Iteration: 270000\n",
      "Coef: [0.87037269 1.00306704 0.36130416]\n",
      "Loss: 0.2518997358276041\n",
      "Iteration: 280000\n",
      "Coef: [0.86804404 1.00538262 0.36131095]\n",
      "Loss: 0.2518995256545204\n",
      "Iteration: 290000\n",
      "Coef: [0.86571462 1.0076971  0.36130799]\n",
      "Loss: 0.25189931550761413\n",
      "Iteration: 300000\n",
      "Coef: [0.86338517 1.01001266 0.36131041]\n",
      "Loss: 0.25189910525926335\n",
      "Iteration: 310000\n",
      "Coef: [0.86105694 1.01232791 0.36131775]\n",
      "Loss: 0.2518988963431621\n",
      "Iteration: 320000\n",
      "Coef: [0.85872814 1.01464174 0.36131451]\n",
      "Loss: 0.25189868552439315\n",
      "Iteration: 330000\n",
      "Coef: [0.85640028 1.01695653 0.36132132]\n",
      "Loss: 0.25189847554455363\n",
      "Iteration: 340000\n",
      "Coef: [0.85407163 1.01927022 0.36131814]\n",
      "Loss: 0.25189826557547795\n",
      "Iteration: 350000\n",
      "Coef: [0.85174295 1.02158498 0.3613205 ]\n",
      "Loss: 0.2518980554681938\n",
      "Iteration: 360000\n",
      "Coef: [0.84941562 1.02389937 0.36132792]\n",
      "Loss: 0.25189784650410435\n",
      "Iteration: 370000\n",
      "Coef: [0.84708761 1.02621245 0.3613249 ]\n",
      "Loss: 0.25189763592209763\n",
      "Iteration: 380000\n",
      "Coef: [0.84476052 1.02852645 0.36133162]\n",
      "Loss: 0.2518974261230059\n",
      "Iteration: 390000\n",
      "Coef: [0.84243265 1.03083934 0.36132831]\n",
      "Loss: 0.25189721636231766\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1b9f2d155d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear_Regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d9ef8e9a2423>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print(self.X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m#self.coef = self.init_weight #### Please change this after you get the example right.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d9ef8e9a2423>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d9ef8e9a2423>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m#self.grad_coef = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = Linear_Regression(alpha = 1, num_iter = 5000000)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805.5669096664781"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((clf.predict(X) - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
