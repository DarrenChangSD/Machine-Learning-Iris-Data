{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments completed for all 150 instances. Here they are:\n",
      "[0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 2. 1. 1. 2. 1. 2. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1.\n",
      " 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Now calculating the new centroids...\n",
      "\n",
      "New centroids have been created. Here they are:\n",
      "[[0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "Cluster assignments completed for all 150 instances. Here they are:\n",
      "[0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 2. 1. 1. 2. 1. 1. 1. 2. 0. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 2. 1. 1.\n",
      " 1. 1. 2. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 0. 1.]\n",
      "\n",
      "Now calculating the new centroids...\n",
      "\n",
      "New centroids have been created. Here they are:\n",
      "[[0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "\n",
      "Cluster membership is unchanged. Stopping criteria has been met.\n",
      "\n",
      "Calculating the Silhouette Coefficients. Please wait...\n",
      "\n",
      "\n",
      "\n",
      "Data Set\n",
      "     Instance  Sepal Length in cm  Sepal Width in cm  Petal Length in cm  \\\n",
      "0           1                   0                  1                   0   \n",
      "1           2                   0                  0                   0   \n",
      "2           3                   0                  1                   0   \n",
      "3           4                   0                  1                   0   \n",
      "4           5                   0                  1                   0   \n",
      "5           6                   0                  1                   0   \n",
      "6           7                   0                  1                   0   \n",
      "7           8                   0                  1                   0   \n",
      "8           9                   0                  0                   0   \n",
      "9          10                   0                  1                   0   \n",
      "10         11                   0                  1                   0   \n",
      "11         12                   0                  1                   0   \n",
      "12         13                   0                  0                   0   \n",
      "13         14                   0                  0                   0   \n",
      "14         15                   0                  1                   0   \n",
      "15         16                   0                  1                   0   \n",
      "16         17                   0                  1                   0   \n",
      "17         18                   0                  1                   0   \n",
      "18         19                   0                  1                   0   \n",
      "19         20                   0                  1                   0   \n",
      "20         21                   0                  1                   0   \n",
      "21         22                   0                  1                   0   \n",
      "22         23                   0                  1                   0   \n",
      "23         24                   0                  1                   0   \n",
      "24         25                   0                  1                   0   \n",
      "25         26                   0                  0                   0   \n",
      "26         27                   0                  1                   0   \n",
      "27         28                   0                  1                   0   \n",
      "28         29                   0                  1                   0   \n",
      "29         30                   0                  1                   0   \n",
      "..        ...                 ...                ...                 ...   \n",
      "120       121                   1                  1                   1   \n",
      "121       122                   0                  0                   1   \n",
      "122       123                   1                  0                   1   \n",
      "123       124                   1                  0                   1   \n",
      "124       125                   1                  1                   1   \n",
      "125       126                   1                  1                   1   \n",
      "126       127                   1                  0                   1   \n",
      "127       128                   1                  0                   1   \n",
      "128       129                   1                  0                   1   \n",
      "129       130                   1                  0                   1   \n",
      "130       131                   1                  0                   1   \n",
      "131       132                   1                  1                   1   \n",
      "132       133                   1                  0                   1   \n",
      "133       134                   1                  0                   1   \n",
      "134       135                   1                  0                   1   \n",
      "135       136                   1                  0                   1   \n",
      "136       137                   1                  1                   1   \n",
      "137       138                   1                  1                   1   \n",
      "138       139                   1                  0                   1   \n",
      "139       140                   1                  1                   1   \n",
      "140       141                   1                  1                   1   \n",
      "141       142                   1                  1                   1   \n",
      "142       143                   0                  0                   1   \n",
      "143       144                   1                  1                   1   \n",
      "144       145                   1                  1                   1   \n",
      "145       146                   1                  0                   1   \n",
      "146       147                   1                  0                   1   \n",
      "147       148                   1                  0                   1   \n",
      "148       149                   1                  1                   1   \n",
      "149       150                   1                  0                   1   \n",
      "\n",
      "     Petal Width in cm           Class  Cluster  Silhouette Coefficient  \\\n",
      "0                    0     Iris-setosa      0.0                0.371080   \n",
      "1                    0     Iris-setosa      2.0                0.951449   \n",
      "2                    0     Iris-setosa      0.0                0.371080   \n",
      "3                    0     Iris-setosa      0.0                0.371080   \n",
      "4                    0     Iris-setosa      0.0                0.371080   \n",
      "5                    0     Iris-setosa      0.0                0.371080   \n",
      "6                    0     Iris-setosa      0.0                0.371080   \n",
      "7                    0     Iris-setosa      0.0                0.371080   \n",
      "8                    0     Iris-setosa      2.0                0.951449   \n",
      "9                    0     Iris-setosa      0.0                0.371080   \n",
      "10                   0     Iris-setosa      0.0                0.371080   \n",
      "11                   0     Iris-setosa      0.0                0.371080   \n",
      "12                   0     Iris-setosa      2.0                0.951449   \n",
      "13                   0     Iris-setosa      2.0                0.951449   \n",
      "14                   0     Iris-setosa      0.0                0.371080   \n",
      "15                   0     Iris-setosa      0.0                0.371080   \n",
      "16                   0     Iris-setosa      0.0                0.371080   \n",
      "17                   0     Iris-setosa      0.0                0.371080   \n",
      "18                   0     Iris-setosa      0.0                0.371080   \n",
      "19                   0     Iris-setosa      0.0                0.371080   \n",
      "20                   0     Iris-setosa      0.0                0.371080   \n",
      "21                   0     Iris-setosa      0.0                0.371080   \n",
      "22                   0     Iris-setosa      0.0                0.371080   \n",
      "23                   0     Iris-setosa      0.0                0.371080   \n",
      "24                   0     Iris-setosa      0.0                0.371080   \n",
      "25                   0     Iris-setosa      2.0                0.951449   \n",
      "26                   0     Iris-setosa      0.0                0.371080   \n",
      "27                   0     Iris-setosa      0.0                0.371080   \n",
      "28                   0     Iris-setosa      0.0                0.371080   \n",
      "29                   0     Iris-setosa      0.0                0.371080   \n",
      "..                 ...             ...      ...                     ...   \n",
      "120                  1  Iris-virginica      0.0                0.064171   \n",
      "121                  1  Iris-virginica      1.0                0.486532   \n",
      "122                  1  Iris-virginica      1.0                0.771822   \n",
      "123                  1  Iris-virginica      1.0                0.771822   \n",
      "124                  1  Iris-virginica      0.0                0.064171   \n",
      "125                  1  Iris-virginica      0.0                0.064171   \n",
      "126                  1  Iris-virginica      1.0                0.771822   \n",
      "127                  1  Iris-virginica      1.0                0.771822   \n",
      "128                  1  Iris-virginica      1.0                0.771822   \n",
      "129                  1  Iris-virginica      1.0                0.771822   \n",
      "130                  1  Iris-virginica      1.0                0.771822   \n",
      "131                  1  Iris-virginica      0.0                0.064171   \n",
      "132                  1  Iris-virginica      1.0                0.771822   \n",
      "133                  1  Iris-virginica      1.0                0.771822   \n",
      "134                  1  Iris-virginica      1.0                0.771822   \n",
      "135                  1  Iris-virginica      1.0                0.771822   \n",
      "136                  1  Iris-virginica      0.0                0.064171   \n",
      "137                  1  Iris-virginica      0.0                0.064171   \n",
      "138                  1  Iris-virginica      1.0                0.771822   \n",
      "139                  1  Iris-virginica      0.0                0.064171   \n",
      "140                  1  Iris-virginica      0.0                0.064171   \n",
      "141                  1  Iris-virginica      0.0                0.064171   \n",
      "142                  1  Iris-virginica      1.0                0.486532   \n",
      "143                  1  Iris-virginica      0.0                0.064171   \n",
      "144                  1  Iris-virginica      0.0                0.064171   \n",
      "145                  1  Iris-virginica      1.0                0.771822   \n",
      "146                  1  Iris-virginica      1.0                0.771822   \n",
      "147                  1  Iris-virginica      1.0                0.771822   \n",
      "148                  1  Iris-virginica      0.0                0.064171   \n",
      "149                  1  Iris-virginica      1.0                0.771822   \n",
      "\n",
      "     Predicted Class  Prediction Correct?  \n",
      "0        Iris-setosa                  1.0  \n",
      "1        Iris-setosa                  1.0  \n",
      "2        Iris-setosa                  1.0  \n",
      "3        Iris-setosa                  1.0  \n",
      "4        Iris-setosa                  1.0  \n",
      "5        Iris-setosa                  1.0  \n",
      "6        Iris-setosa                  1.0  \n",
      "7        Iris-setosa                  1.0  \n",
      "8        Iris-setosa                  1.0  \n",
      "9        Iris-setosa                  1.0  \n",
      "10       Iris-setosa                  1.0  \n",
      "11       Iris-setosa                  1.0  \n",
      "12       Iris-setosa                  1.0  \n",
      "13       Iris-setosa                  1.0  \n",
      "14       Iris-setosa                  1.0  \n",
      "15       Iris-setosa                  1.0  \n",
      "16       Iris-setosa                  1.0  \n",
      "17       Iris-setosa                  1.0  \n",
      "18       Iris-setosa                  1.0  \n",
      "19       Iris-setosa                  1.0  \n",
      "20       Iris-setosa                  1.0  \n",
      "21       Iris-setosa                  1.0  \n",
      "22       Iris-setosa                  1.0  \n",
      "23       Iris-setosa                  1.0  \n",
      "24       Iris-setosa                  1.0  \n",
      "25       Iris-setosa                  1.0  \n",
      "26       Iris-setosa                  1.0  \n",
      "27       Iris-setosa                  1.0  \n",
      "28       Iris-setosa                  1.0  \n",
      "29       Iris-setosa                  1.0  \n",
      "..               ...                  ...  \n",
      "120      Iris-setosa                  0.0  \n",
      "121  Iris-versicolor                  0.0  \n",
      "122  Iris-versicolor                  0.0  \n",
      "123  Iris-versicolor                  0.0  \n",
      "124      Iris-setosa                  0.0  \n",
      "125      Iris-setosa                  0.0  \n",
      "126  Iris-versicolor                  0.0  \n",
      "127  Iris-versicolor                  0.0  \n",
      "128  Iris-versicolor                  0.0  \n",
      "129  Iris-versicolor                  0.0  \n",
      "130  Iris-versicolor                  0.0  \n",
      "131      Iris-setosa                  0.0  \n",
      "132  Iris-versicolor                  0.0  \n",
      "133  Iris-versicolor                  0.0  \n",
      "134  Iris-versicolor                  0.0  \n",
      "135  Iris-versicolor                  0.0  \n",
      "136      Iris-setosa                  0.0  \n",
      "137      Iris-setosa                  0.0  \n",
      "138  Iris-versicolor                  0.0  \n",
      "139      Iris-setosa                  0.0  \n",
      "140      Iris-setosa                  0.0  \n",
      "141      Iris-setosa                  0.0  \n",
      "142  Iris-versicolor                  0.0  \n",
      "143      Iris-setosa                  0.0  \n",
      "144      Iris-setosa                  0.0  \n",
      "145  Iris-versicolor                  0.0  \n",
      "146  Iris-versicolor                  0.0  \n",
      "147  Iris-versicolor                  0.0  \n",
      "148      Iris-setosa                  0.0  \n",
      "149  Iris-versicolor                  0.0  \n",
      "\n",
      "[150 rows x 10 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "K-means Summary Statistics (Testing)\n",
      "-------------------------------------------------------\n",
      "Data Set : iris_dataset.txt\n",
      "\n",
      "Number of Instances : 150\n",
      "Value for k : 3\n",
      "Silhouette Coefficient : 0.49485800378829764\n",
      "Accuracy : 56.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Import Pandas library \n",
    "import numpy as np # Import Numpy library\n",
    " \n",
    "# File name: kmeans.py\n",
    "# Author: Addison Sears-Collins\n",
    "# Date created: 6/12/2019\n",
    "# Python version: 3.7\n",
    "# Description: Implementation of K-means clustering algorithm from scratch.\n",
    "# K-means algorithm is a clustering algorithm that is used to group \n",
    "# unlabeled data set instances into clusters based on similar attributes.\n",
    " \n",
    "# Required Data Set Format:\n",
    "# Columns (0 through N)\n",
    "# 0: Instance ID\n",
    "# 1: Attribute 1 \n",
    "# 2: Attribute 2\n",
    "# 3: Attribute 3 \n",
    "# ...\n",
    "# N: Actual Class (used for classification accuracy calculation)\n",
    " \n",
    "# This program then adds 4 additional columns.\n",
    "# N + 1: Cluster\n",
    "# N + 2: Silhouette Coefficient\n",
    "# N + 3: Predicted Class\n",
    "# N + 4: Prediction Correct? (1 if yes, 0 if no)\n",
    " \n",
    "################ INPUT YOUR OWN VALUES IN THIS SECTION ######################\n",
    "ALGORITHM_NAME = \"K-means\"\n",
    "DATA_PATH = \"iris_dataset.txt\"  # Directory where data set is located\n",
    "TEST_STATS_FILE = \"iris_dataset_kmeans_test_stats.txt\"#Testing statistics\n",
    "TEST_OUT_FILE = \"iris_dataset_kmeans_test_out.txt\" # Testing output\n",
    "# Show functioning of the program\n",
    "TRACE_RUNS_FILE  = \"iris_dataset_kmeans_trace_runs.txt\"\n",
    "SEPARATOR = \",\"  # Separator for the data set (e.g. \"\\t\" for tab data)\n",
    "#############################################################################\n",
    " \n",
    "# Open a new file to save trace runs\n",
    "outfile3 = open(TRACE_RUNS_FILE,\"w\") \n",
    " \n",
    "# Read the full text file and store records in a Pandas dataframe\n",
    "pd_full_data_set = pd.read_csv(DATA_PATH, sep=SEPARATOR)\n",
    " \n",
    "# Copy the dataframe into a new dataframe so we don't mess up the\n",
    "# original data\n",
    "pd_data_set = pd_full_data_set.copy() \n",
    " \n",
    "# Calculate the number of instances, columns, and attributes in the\n",
    "# training data set. Assumes 1 column for the instance ID and 1 column\n",
    "# for the class. Record the index of the column that contains \n",
    "# the actual class\n",
    "no_of_instances = len(pd_data_set.index) # number of rows\n",
    "no_of_columns = len(pd_data_set.columns) # number of columns\n",
    "no_of_attributes = no_of_columns - 2\n",
    "actual_class_column = no_of_columns - 1\n",
    " \n",
    "# Store class values in a column and then create a list of unique\n",
    "# classes and store in a dataframe and a Numpy array\n",
    "unique_class_list_df = pd_data_set.iloc[:,actual_class_column]\n",
    "unique_class_list_np = unique_class_list_df.unique() #Numpy array\n",
    "unique_class_list_df = unique_class_list_df.drop_duplicates()#Pandas df\n",
    " \n",
    "# Record the number of unique classes in the data set\n",
    "num_unique_classes = len(unique_class_list_df)\n",
    " \n",
    "# Record the value for K, the number of clusters\n",
    "K = num_unique_classes\n",
    " \n",
    "# Remove the Instance and the Actual Class Column to create an unlabled\n",
    "# data set\n",
    "instance_id_colname = pd_data_set.columns[0]\n",
    "class_column_colname = pd_data_set.columns[actual_class_column]\n",
    "pd_data_set = pd_data_set.drop(columns = [ # Each row is a different instance\n",
    "        instance_id_colname, class_column_colname]) \n",
    " \n",
    "# Convert dataframe into a Numpy array\n",
    "np_data_set = pd_data_set.to_numpy(copy=True)\n",
    " \n",
    "# Randomly select k instances from the data set. \n",
    "# These will be the cluster centroids for the first iteration\n",
    "# of the algorithm.\n",
    "centroids = np_data_set[np.random.choice(np_data_set.shape[\n",
    "    0], size=K, replace=False), :]\n",
    "\n",
    "# Go through each instance and assign that instance to the closest \n",
    "# centroid (based on Euclidean distance).\n",
    " \n",
    "# Initialize an array which will contain the cluster assignments for each\n",
    "# instance.\n",
    "cluster_assignments = np.empty(no_of_instances)\n",
    " \n",
    "# Goes True if new centroids are the same as the old centroids\n",
    "centroids_the_same = False\n",
    " \n",
    "# Sets the maximum number of iterations\n",
    "max_iterations = 300\n",
    " \n",
    "while max_iterations > 0 and not(centroids_the_same):\n",
    "    # Go through each data point and assign it to the nearest centroid\n",
    "    for row in range(0, no_of_instances):\n",
    "     \n",
    "        this_instance = np_data_set[row]\n",
    " \n",
    "        # Calculate the Euclidean distance of each instance in the data set\n",
    "        # from each of the centroids\n",
    "        # Find the centroid with the minimum distance and assign the instance\n",
    "        # to that centroid.\n",
    "        # Record that centroid in the cluster assignments array.\n",
    "     \n",
    "        # Reset the minimum distance to infinity\n",
    "        min_distance = float(\"inf\")\n",
    " \n",
    "        for row_centroid in range(0, K):\n",
    "            this_centroid = centroids[row_centroid]\n",
    "         \n",
    "            # Calculate the Euclidean distance from this instance to the\n",
    "            # centroid\n",
    "            distance = np.linalg.norm(this_instance - this_centroid)\n",
    " \n",
    "            # If we have a centroid that is closer to this instance,\n",
    "            # update the cluster assignment for this instance.\n",
    "            if distance < min_distance:\n",
    "                cluster_assignments[row] = row_centroid\n",
    "                min_distance = distance # Update the minimum distance\n",
    " \n",
    "    # Print after each cluster assignment has completed\n",
    "    print(\"Cluster assignments completed for all \" + str(\n",
    "        no_of_instances) + \" instances. Here they are:\")\n",
    "    print(cluster_assignments)\n",
    "    print()\n",
    "    print(\"Now calculating the new centroids...\")\n",
    "    print()\n",
    " \n",
    "    outfile3.write(\"Cluster assignments completed for all \" + str(\n",
    "        no_of_instances) + \" instances. Here they are:\"+ \"\\n\")\n",
    "    outfile3.write(str(cluster_assignments))\n",
    "    outfile3.write(\"\\n\")\n",
    "    outfile3.write(\"\\n\")\n",
    "    outfile3.write(\"Now calculating the new centroids...\" + \"\\n\")\n",
    "    outfile3.write(\"\\n\")\n",
    "     \n",
    "        \n",
    "        \n",
    "    ##################### Move Centroid Step ################################\n",
    "    # Calculate the centroids of the clusters by computing the average\n",
    "    # of the attribute values of the instances in each cluster\n",
    "    # For each row in the centroids 2D array\n",
    " \n",
    "    # Store the old centroids\n",
    "    old_centroids = centroids.copy()\n",
    " \n",
    "    for row_centroid in range(0, K):\n",
    " \n",
    "        # For each column of each row of the centroids 2D array\n",
    "        for col_centroid in range(0, no_of_attributes):\n",
    " \n",
    "            # Reset the running sum and the counter\n",
    "            running_sum = 0.0\n",
    "            count = 0.0\n",
    "            average = None\n",
    " \n",
    "            for row in range(0, no_of_instances):\n",
    " \n",
    "                # If this instance belongs to this cluster\n",
    "                if(row_centroid == cluster_assignments[row]):\n",
    "                 \n",
    "                    # Add this value to the running sum\n",
    "                    running_sum += np_data_set[row,col_centroid]\n",
    "                     \n",
    "                    # Increment the counter\n",
    "                    count += 1\n",
    "         \n",
    "                    if (count > 0):\n",
    "                        # Calculate the average\n",
    "                        average = running_sum / count\n",
    " \n",
    "            # Update the centroids array with this average\n",
    "            centroids[row_centroid,col_centroid] = average\n",
    "     \n",
    "    # Print to after each cluster assignment has completed\n",
    "    print(\"New centroids have been created. Here they are:\")\n",
    "    print(centroids)\n",
    "    print()\n",
    " \n",
    "    outfile3.write(\"New centroids have been created. Here they are:\" + \"\\n\")\n",
    "    outfile3.write(str(centroids))\n",
    "    outfile3.write(\"\\n\")\n",
    "    outfile3.write(\"\\n\")\n",
    " \n",
    "    # Check if cluster centroids are the same\n",
    "    centroids_the_same = np.array_equal(old_centroids,centroids)\n",
    " \n",
    "    if centroids_the_same:\n",
    "        print(\n",
    "        \"Cluster membership is unchanged. Stopping criteria has been met.\")\n",
    "        outfile3.write(\"Cluster membership is unchanged. \")\n",
    "        outfile3.write(\"Stopping criteria has been met.\" + \"\\n\")\n",
    "        outfile3.write(\"\\n\")\n",
    " \n",
    "    # Update the number of iterations\n",
    "    max_iterations -= 1\n",
    "\n",
    "\n",
    "actual_class_col_name = pd_full_data_set.columns[len(\n",
    "    pd_full_data_set.columns) - 1]\n",
    " \n",
    "# Add 4 additional columns to the original data frame\n",
    "pd_full_data_set = pd_full_data_set.reindex(\n",
    "      columns=[*pd_full_data_set.columns.tolist(\n",
    "      ), 'Cluster', 'Silhouette Coefficient', 'Predicted Class', (\n",
    "      'Prediction Correct?')])\n",
    " \n",
    "# Add the final cluster assignments to the Pandas dataframe\n",
    "pd_full_data_set['Cluster'] = cluster_assignments\n",
    " \n",
    "outfile3.write(\"Calculating the Silhouette Coefficients. Please wait...\" + \"\\n\")\n",
    "outfile3.write(\"\\n\")\n",
    "print()\n",
    "print(\"Calculating the Silhouette Coefficients. Please wait...\")\n",
    "print()\n",
    "################## Calculate the Silhouette Coefficients ######################\n",
    "# Rewards clusterings that have good cohesion and good separation. Varies \n",
    "# between 1 and -1. -1 means bad clustering, 1 means great clustering.\n",
    " \n",
    "# 1. For each instance calculate the average distance to all other instances \n",
    "# in that cluster. This is a.\n",
    "# 2. (Find the average distance to all the instances in the nearest neighbor \n",
    "# cluster). For each instance and any cluster that does not contain the \n",
    "# instance calculate the average distance to all\n",
    "# of the points in that other cluster. Then return the minimum such value\n",
    "# over all of the clusters. This is b.\n",
    "# 3. For each instance calculate the Silhouette Coefficient s where\n",
    "# s = (b-a)/max(a,b)\n",
    "# Store the value in the data frame\n",
    " \n",
    "silhouette_column = actual_class_column + 2\n",
    " \n",
    "# Go through one instance at a time\n",
    "for row in range(0, no_of_instances):\n",
    " \n",
    "    this_instance = np_data_set[row]\n",
    "    this_cluster = cluster_assignments[row]\n",
    " \n",
    "    a = None\n",
    "    running_sum = 0.0\n",
    "    counter = 0.0\n",
    " \n",
    "    # Calculate the average distance to all other instances \n",
    "    # in this cluster. This is a.\n",
    "    # Go through one instance at a time\n",
    "    for row_2 in range(0, no_of_instances):\n",
    " \n",
    "        # If the other instance is in the same cluster as this instance\n",
    "        if this_cluster == cluster_assignments[row_2]:\n",
    " \n",
    "            # Calculate the distance\n",
    "            distance = np.linalg.norm(this_instance - np_data_set[row_2])\n",
    " \n",
    "            # Add the distance to the running sum\n",
    "            running_sum += distance\n",
    "            counter += 1\n",
    " \n",
    "    # Calculate the value for a\n",
    "    if counter > 0:\n",
    "        a = running_sum / counter\n",
    " \n",
    "    # For each instance and any cluster that does not contain the \n",
    "    # instance calculate the average distance to all\n",
    "    # of the points in that other cluster. Then return the minimum such value\n",
    "    # over all of the clusters. This is b.\n",
    "    b = float(\"inf\") \n",
    "     \n",
    "    for clstr in range(0, K):\n",
    " \n",
    "        running_sum = 0.0\n",
    "        counter = 0.0\n",
    " \n",
    "        # Must be other clusters, not the one this instance is in\n",
    "        if clstr != this_cluster:\n",
    " \n",
    "            # Calculate the average distance to instances in that \n",
    "            # other cluster\n",
    "            for row_3 in range(0, no_of_instances):\n",
    " \n",
    "                if cluster_assignments[row_3] == clstr:\n",
    " \n",
    "                    # Calculate the distance\n",
    "                    distance = np.linalg.norm(this_instance - np_data_set[\n",
    "                        row_3])\n",
    " \n",
    "                    # Add the distance to the running sum\n",
    "                    running_sum += distance\n",
    "                    counter += 1\n",
    "         \n",
    "            if counter > 0:\n",
    "                avg_distance_to_cluster = running_sum / counter\n",
    "         \n",
    "            # Update b if we have a new minimum\n",
    "            if avg_distance_to_cluster < b:\n",
    "                b = avg_distance_to_cluster\n",
    " \n",
    "    # Calculate the Silhouette Coefficient s where s = (b-a)/max(a,b)\n",
    "    s = (b - a) / max(a,b)\n",
    " \n",
    "    # Store the Silhouette Coefficient in the Pandas data frame\n",
    "    pd_full_data_set.iloc[row,silhouette_column] = s\n",
    "\n",
    "# For each cluster, determine the predominant class and assign that \n",
    "# class to the cluster. Then determine if the prediction was correct.\n",
    "# Create a data frame that maps clusters to actual classes\n",
    "class_mappings = pd.DataFrame(index=range(K),columns=range(1))\n",
    " \n",
    "for clstr in range(0, K):\n",
    " \n",
    "    # Select rows whose column equals that cluster value\n",
    "    temp_df = pd_full_data_set.loc[pd_full_data_set['Cluster'] == clstr]\n",
    "     \n",
    "    # Select the predominant class\n",
    "    class_mappings.iloc[clstr,0] = temp_df.mode()[actual_class_col_name][0]\n",
    "    \n",
    "cluster_column = actual_class_column + 1\n",
    "pred_class_column = actual_class_column + 3\n",
    "pred_correct_column = actual_class_column + 4\n",
    " \n",
    "# Assign the relevant class to each instance\n",
    "# See if prediction was correct\n",
    "for row in range(0, no_of_instances):\n",
    " \n",
    "    # Go through each of the clusters to check if the instance is a member\n",
    "    # of that cluster\n",
    "    for clstr in range(0, K):\n",
    "        if clstr == pd_full_data_set.iloc[row,cluster_column]:\n",
    " \n",
    "            # Assign the relevant class to this instance\n",
    "            pd_full_data_set.iloc[\n",
    "                row,pred_class_column] = class_mappings.iloc[clstr,0]\n",
    " \n",
    "    # If the prediction was correct\n",
    "    if pd_full_data_set.iloc[row,pred_class_column] == pd_full_data_set.iloc[\n",
    "        row,actual_class_column]:\n",
    "        pd_full_data_set.iloc[row,pred_correct_column] = 1\n",
    "    else: # If incorrect prediction\n",
    "        pd_full_data_set.iloc[row,pred_correct_column] = 0\n",
    "        \n",
    "\n",
    "pd_full_data_set.to_csv(TEST_OUT_FILE, sep=\",\", header=True)\n",
    " \n",
    "# Print data frame to the console\n",
    "print()\n",
    "print()\n",
    "print(\"Data Set\")\n",
    "print(pd_full_data_set)\n",
    "print()\n",
    "print()\n",
    " \n",
    "################### Summary Statistics #######################################\n",
    "# Calculate the average Silhouette Coefficient for the data set\n",
    "# Calculate the accuracy of the clustering-based classifier\n",
    " \n",
    "# Open a new file to save the summary statistics\n",
    "outfile1 = open(TEST_STATS_FILE,\"w\") \n",
    " \n",
    "# Write to a file\n",
    "outfile1.write(\"----------------------------------------------------------\\n\")\n",
    "outfile1.write(ALGORITHM_NAME + \" Summary Statistics (Testing)\\n\")\n",
    "outfile1.write(\"----------------------------------------------------------\\n\")\n",
    "outfile1.write(\"Data Set : \" + DATA_PATH + \"\\n\")\n",
    " \n",
    "# Write the relevant stats to a file\n",
    "outfile1.write(\"\\n\")\n",
    "outfile1.write(\"Number of Instances : \" + str(no_of_instances) + \"\\n\")\n",
    "outfile1.write(\"\\n\")\n",
    "outfile1.write(\"Value for k : \" + str(K) + \"\\n\")\n",
    " \n",
    "# Calculate average Silhouette Coefficient for the data set\n",
    "silhouette_coefficient = pd_full_data_set.loc[\n",
    "    :,\"Silhouette Coefficient\"].mean()\n",
    " \n",
    "# Write the Silhouette Coefficient to the file\n",
    "outfile1.write(\"Silhouette Coefficient : \" + str(\n",
    "    silhouette_coefficient) + \"\\n\")\n",
    "       \n",
    "# accuracy = (total correct predictions)/(total number of predictions)\n",
    "accuracy = (pd_full_data_set.iloc[\n",
    "        :,pred_correct_column].sum())/no_of_instances\n",
    " \n",
    "accuracy *= 100\n",
    " \n",
    "# Write accuracy to the file\n",
    "outfile1.write(\"Accuracy : \" + str(accuracy) + \"%\\n\")\n",
    " \n",
    "# Print statistics to console\n",
    "print()\n",
    "print()\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(ALGORITHM_NAME + \" Summary Statistics (Testing)\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Data Set : \" + DATA_PATH)\n",
    " \n",
    "# Print the relevant stats to the console\n",
    "print()\n",
    "print(\"Number of Instances : \" + str(no_of_instances))\n",
    "print(\"Value for k : \" + str(K))\n",
    " \n",
    "# Print the Silhouette Coefficient to the console\n",
    "print(\"Silhouette Coefficient : \" + str(\n",
    "    silhouette_coefficient))\n",
    " \n",
    "# Print accuracy to the console\n",
    "print(\"Accuracy : \" + str(accuracy) + \"%\")\n",
    " \n",
    "# Close the files\n",
    "outfile1.close()\n",
    "outfile3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
